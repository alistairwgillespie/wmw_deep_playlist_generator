{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilson's Morning Wake Up Playlist Generator, Modeling and Learning\n",
    "\n",
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import config\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PlaylistDataset\n",
    "\n",
    "dataset =  PlaylistDataset.PlaylistDataset(data_dir, \"tensor_train.csv\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "It's time to define and train the models!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Estimator\n",
    "\n",
    "## Define PyTorch estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of benchmark and candidate models and train components\n",
    "Here I will see if the configurations I have set work accordingly with no errors. Once it runs smoothly, I will instantiate the estimators using the Sagemaker API in the AWS notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the train function for training the baseline RNN model and candidate, LSTM model. Each model excepts a tensor of 9 features. For feed-forward behaviour, a single track - as input - along with with a hidden state is accepted, which is then used to predict the features of the following track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for LSTM\n",
    "def train(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script of the LSTM model. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    criterion    - The loss function used for training. \n",
    "    optimizer    - The optimizer to use during training.\n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train() # Make sure that the model is in training mode.\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        avg_loss = 0\n",
    "        \n",
    "        # Iterate over dataset\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            \n",
    "            # Clear stored gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Initialize hidden state \n",
    "            hidden_cell = model.init_hidden()\n",
    "            \n",
    "            # Batch of 12 tracks\n",
    "            batch_x = batch[0] # X input\n",
    "            batch_y = batch[-1] # y target\n",
    "            \n",
    "            # Forward pass\n",
    "            output, hidden_cell = model(batch_x.unsqueeze(0), hidden_cell)\n",
    "            \n",
    "            # Calculate MAE loss over batch\n",
    "            batch_loss = criterion(output.squeeze(0), batch_y)\n",
    "            avg_loss += batch_loss.item()\n",
    "            \n",
    "            # Zero out gradient, so it doesnt accumulate between epochs\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_record.append(avg_loss / len(train_loader))\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(avg_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# torch imports\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class RNNEstimator(nn.Module):\n",
      "    \"\"\"\n",
      "    RNN Estimator for generating sequences of target variables.\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, input_features=9, hidden_dim=12, n_layers=2, output_dim=9, batch_size=12):\n",
      "        super(RNNEstimator, self).__init__()\n",
      "\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.hidden_layers = n_layers\n",
      "        self.batch_size = batch_size\n",
      "        \n",
      "        # RNN Layer\n",
      "        self.rnn = nn.RNN(input_features, hidden_dim, n_layers, dropout=0.3)\n",
      "        \n",
      "        # Fully connected layer\n",
      "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
      "        \n",
      "    ## Initialize the hidden and cell states of the LSTM with zeros.\n",
      "    def init_hidden(self):\n",
      "        return torch.zeros(self.hidden_layers, self.batch_size, self.hidden_dim)\n",
      "        \n",
      "    ## Define the feedforward behavior of the network\n",
      "    def forward(self, input, hidden_state):\n",
      "        \n",
      "        # Passing in the input and hidden state into the model and obtaining outputs\n",
      "        output, hidden_state = self.rnn(input.view(len(input), self.batch_size, -1), hidden_state)\n",
      "        \n",
      "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
      "        output = self.fc(output)\n",
      "        \n",
      "        return output, hidden_state\n"
     ]
    }
   ],
   "source": [
    "# Directory of RnnEstimator.py\n",
    "!pygmentize model/RNNEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch: 50/10000............. Loss: 0.6229\n",
      "Epoch: 100/10000............. Loss: 0.6187\n",
      "Epoch: 150/10000............. Loss: 0.6176\n",
      "Epoch: 200/10000............. Loss: 0.6129\n",
      "Epoch: 250/10000............. Loss: 0.6093\n",
      "Epoch: 300/10000............. Loss: 0.6106\n",
      "Epoch: 350/10000............. Loss: 0.6064\n",
      "Epoch: 400/10000............. Loss: 0.6057\n",
      "Epoch: 450/10000............. Loss: 0.6081\n",
      "Epoch: 500/10000............. Loss: 0.6054\n",
      "Epoch: 550/10000............. Loss: 0.6029\n",
      "Epoch: 600/10000............. Loss: 0.6014\n",
      "Epoch: 650/10000............. Loss: 0.5944\n",
      "Epoch: 700/10000............. Loss: 0.5998\n",
      "Epoch: 750/10000............. Loss: 0.5984\n",
      "Epoch: 800/10000............. Loss: 0.6004\n",
      "Epoch: 850/10000............. Loss: 0.6038\n",
      "Epoch: 900/10000............. Loss: 0.5974\n",
      "Epoch: 950/10000............. Loss: 0.5992\n",
      "Epoch: 1000/10000............. Loss: 0.5994\n",
      "Epoch: 1050/10000............. Loss: 0.5988\n",
      "Epoch: 1100/10000............. Loss: 0.5954\n",
      "Epoch: 1150/10000............. Loss: 0.5952\n",
      "Epoch: 1200/10000............. Loss: 0.5964\n",
      "Epoch: 1250/10000............. Loss: 0.5903\n",
      "Epoch: 1300/10000............. Loss: 0.5886\n",
      "Epoch: 1350/10000............. Loss: 0.5902\n",
      "Epoch: 1400/10000............. Loss: 0.5899\n",
      "Epoch: 1450/10000............. Loss: 0.5908\n",
      "Epoch: 1500/10000............. Loss: 0.5934\n",
      "Epoch: 1550/10000............. Loss: 0.5945\n",
      "Epoch: 1600/10000............. Loss: 0.5951\n",
      "Epoch: 1650/10000............. Loss: 0.5926\n",
      "Epoch: 1700/10000............. Loss: 0.5913\n",
      "Epoch: 1750/10000............. Loss: 0.5957\n",
      "Epoch: 1800/10000............. Loss: 0.5884\n",
      "Epoch: 1850/10000............. Loss: 0.5953\n",
      "Epoch: 1900/10000............. Loss: 0.5864\n",
      "Epoch: 1950/10000............. Loss: 0.5899\n",
      "Epoch: 2000/10000............. Loss: 0.5889\n",
      "Epoch: 2050/10000............. Loss: 0.5879\n",
      "Epoch: 2100/10000............. Loss: 0.5904\n",
      "Epoch: 2150/10000............. Loss: 0.5900\n",
      "Epoch: 2200/10000............. Loss: 0.5920\n",
      "Epoch: 2250/10000............. Loss: 0.5896\n",
      "Epoch: 2300/10000............. Loss: 0.5875\n",
      "Epoch: 2350/10000............. Loss: 0.5935\n",
      "Epoch: 2400/10000............. Loss: 0.5911\n",
      "Epoch: 2450/10000............. Loss: 0.5905\n",
      "Epoch: 2500/10000............. Loss: 0.5841\n",
      "Epoch: 2550/10000............. Loss: 0.5873\n",
      "Epoch: 2600/10000............. Loss: 0.5839\n",
      "Epoch: 2650/10000............. Loss: 0.5859\n",
      "Epoch: 2700/10000............. Loss: 0.5883\n",
      "Epoch: 2750/10000............. Loss: 0.5913\n",
      "Epoch: 2800/10000............. Loss: 0.5864\n",
      "Epoch: 2850/10000............. Loss: 0.5862\n",
      "Epoch: 2900/10000............. Loss: 0.5882\n",
      "Epoch: 2950/10000............. Loss: 0.5881\n",
      "Epoch: 3000/10000............. Loss: 0.5879\n",
      "Epoch: 3050/10000............. Loss: 0.5928\n",
      "Epoch: 3100/10000............. Loss: 0.5860\n",
      "Epoch: 3150/10000............. Loss: 0.5873\n",
      "Epoch: 3200/10000............. Loss: 0.5869\n",
      "Epoch: 3250/10000............. Loss: 0.5882\n",
      "Epoch: 3300/10000............. Loss: 0.5867\n",
      "Epoch: 3350/10000............. Loss: 0.5871\n",
      "Epoch: 3400/10000............. Loss: 0.5877\n",
      "Epoch: 3450/10000............. Loss: 0.5917\n",
      "Epoch: 3500/10000............. Loss: 0.5898\n",
      "Epoch: 3550/10000............. Loss: 0.5868\n",
      "Epoch: 3600/10000............. Loss: 0.5864\n",
      "Epoch: 3650/10000............. Loss: 0.5820\n",
      "Epoch: 3700/10000............. Loss: 0.5851\n",
      "Epoch: 3750/10000............. Loss: 0.5897\n",
      "Epoch: 3800/10000............. Loss: 0.5870\n",
      "Epoch: 3850/10000............. Loss: 0.5837\n",
      "Epoch: 3900/10000............. Loss: 0.5867\n",
      "Epoch: 3950/10000............. Loss: 0.5852\n",
      "Epoch: 4000/10000............. Loss: 0.5795\n",
      "Epoch: 4050/10000............. Loss: 0.5852\n",
      "Epoch: 4100/10000............. Loss: 0.5845\n",
      "Epoch: 4150/10000............. Loss: 0.5864\n",
      "Epoch: 4200/10000............. Loss: 0.5843\n",
      "Epoch: 4250/10000............. Loss: 0.5866\n",
      "Epoch: 4300/10000............. Loss: 0.5839\n",
      "Epoch: 4350/10000............. Loss: 0.5864\n",
      "Epoch: 4400/10000............. Loss: 0.5805\n",
      "Epoch: 4450/10000............. Loss: 0.5858\n",
      "Epoch: 4500/10000............. Loss: 0.5867\n",
      "Epoch: 4550/10000............. Loss: 0.5853\n",
      "Epoch: 4600/10000............. Loss: 0.5808\n",
      "Epoch: 4650/10000............. Loss: 0.5874\n",
      "Epoch: 4700/10000............. Loss: 0.5830\n",
      "Epoch: 4750/10000............. Loss: 0.5818\n",
      "Epoch: 4800/10000............. Loss: 0.5812\n",
      "Epoch: 4850/10000............. Loss: 0.5833\n",
      "Epoch: 4900/10000............. Loss: 0.5767\n",
      "Epoch: 4950/10000............. Loss: 0.5861\n",
      "Epoch: 5000/10000............. Loss: 0.5862\n",
      "Epoch: 5050/10000............. Loss: 0.5812\n",
      "Epoch: 5100/10000............. Loss: 0.5830\n",
      "Epoch: 5150/10000............. Loss: 0.5864\n",
      "Epoch: 5200/10000............. Loss: 0.5830\n",
      "Epoch: 5250/10000............. Loss: 0.5867\n",
      "Epoch: 5300/10000............. Loss: 0.5848\n",
      "Epoch: 5350/10000............. Loss: 0.5888\n",
      "Epoch: 5400/10000............. Loss: 0.5899\n",
      "Epoch: 5450/10000............. Loss: 0.5835\n",
      "Epoch: 5500/10000............. Loss: 0.5757\n",
      "Epoch: 5550/10000............. Loss: 0.5874\n",
      "Epoch: 5600/10000............. Loss: 0.5855\n",
      "Epoch: 5650/10000............. Loss: 0.5821\n",
      "Epoch: 5700/10000............. Loss: 0.5870\n",
      "Epoch: 5750/10000............. Loss: 0.5850\n",
      "Epoch: 5800/10000............. Loss: 0.5828\n",
      "Epoch: 5850/10000............. Loss: 0.5768\n",
      "Epoch: 5900/10000............. Loss: 0.5771\n",
      "Epoch: 5950/10000............. Loss: 0.5866\n",
      "Epoch: 6000/10000............. Loss: 0.5818\n",
      "Epoch: 6050/10000............. Loss: 0.5844\n",
      "Epoch: 6100/10000............. Loss: 0.5854\n",
      "Epoch: 6150/10000............. Loss: 0.5821\n",
      "Epoch: 6200/10000............. Loss: 0.5841\n",
      "Epoch: 6250/10000............. Loss: 0.5764\n",
      "Epoch: 6300/10000............. Loss: 0.5766\n",
      "Epoch: 6350/10000............. Loss: 0.5809\n",
      "Epoch: 6400/10000............. Loss: 0.5885\n",
      "Epoch: 6450/10000............. Loss: 0.5833\n",
      "Epoch: 6500/10000............. Loss: 0.5798\n",
      "Epoch: 6550/10000............. Loss: 0.5808\n",
      "Epoch: 6600/10000............. Loss: 0.5782\n",
      "Epoch: 6650/10000............. Loss: 0.5803\n",
      "Epoch: 6700/10000............. Loss: 0.5817\n",
      "Epoch: 6750/10000............. Loss: 0.5825\n",
      "Epoch: 6800/10000............. Loss: 0.5827\n",
      "Epoch: 6850/10000............. Loss: 0.5806\n",
      "Epoch: 6900/10000............. Loss: 0.5800\n",
      "Epoch: 6950/10000............. Loss: 0.5784\n",
      "Epoch: 7000/10000............. Loss: 0.5882\n",
      "Epoch: 7050/10000............. Loss: 0.5832\n",
      "Epoch: 7100/10000............. Loss: 0.5844\n",
      "Epoch: 7150/10000............. Loss: 0.5840\n",
      "Epoch: 7200/10000............. Loss: 0.5805\n",
      "Epoch: 7250/10000............. Loss: 0.5812\n",
      "Epoch: 7300/10000............. Loss: 0.5842\n",
      "Epoch: 7350/10000............. Loss: 0.5768\n",
      "Epoch: 7400/10000............. Loss: 0.5828\n",
      "Epoch: 7450/10000............. Loss: 0.5819\n",
      "Epoch: 7500/10000............. Loss: 0.5823\n",
      "Epoch: 7550/10000............. Loss: 0.5801\n",
      "Epoch: 7600/10000............. Loss: 0.5874\n",
      "Epoch: 7650/10000............. Loss: 0.5791\n",
      "Epoch: 7700/10000............. Loss: 0.5820\n",
      "Epoch: 7750/10000............. Loss: 0.5810\n",
      "Epoch: 7800/10000............. Loss: 0.5823\n",
      "Epoch: 7850/10000............. Loss: 0.5806\n",
      "Epoch: 7900/10000............. Loss: 0.5807\n",
      "Epoch: 7950/10000............. Loss: 0.5871\n",
      "Epoch: 8000/10000............. Loss: 0.5820\n",
      "Epoch: 8050/10000............. Loss: 0.5807\n",
      "Epoch: 8100/10000............. Loss: 0.5834\n",
      "Epoch: 8150/10000............. Loss: 0.5817\n",
      "Epoch: 8200/10000............. Loss: 0.5772\n",
      "Epoch: 8250/10000............. Loss: 0.5831\n",
      "Epoch: 8300/10000............. Loss: 0.5836\n",
      "Epoch: 8350/10000............. Loss: 0.5873\n",
      "Epoch: 8400/10000............. Loss: 0.5833\n",
      "Epoch: 8450/10000............. Loss: 0.5852\n",
      "Epoch: 8500/10000............. Loss: 0.5827\n",
      "Epoch: 8550/10000............. Loss: 0.5789\n",
      "Epoch: 8600/10000............. Loss: 0.5782\n",
      "Epoch: 8650/10000............. Loss: 0.5856\n",
      "Epoch: 8700/10000............. Loss: 0.5807\n",
      "Epoch: 8750/10000............. Loss: 0.5849\n",
      "Epoch: 8800/10000............. Loss: 0.5875\n",
      "Epoch: 8850/10000............. Loss: 0.5792\n",
      "Epoch: 8900/10000............. Loss: 0.5811\n",
      "Epoch: 8950/10000............. Loss: 0.5798\n",
      "Epoch: 9000/10000............. Loss: 0.5798\n",
      "Epoch: 9050/10000............. Loss: 0.5827\n",
      "Epoch: 9100/10000............. Loss: 0.5818\n",
      "Epoch: 9150/10000............. Loss: 0.5819\n",
      "Epoch: 9200/10000............. Loss: 0.5774\n",
      "Epoch: 9250/10000............. Loss: 0.5794\n",
      "Epoch: 9300/10000............. Loss: 0.5795\n",
      "Epoch: 9350/10000............. Loss: 0.5846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9400/10000............. Loss: 0.5833\n",
      "Epoch: 9450/10000............. Loss: 0.5823\n",
      "Epoch: 9500/10000............. Loss: 0.5824\n",
      "Epoch: 9550/10000............. Loss: 0.5744\n",
      "Epoch: 9600/10000............. Loss: 0.5837\n",
      "Epoch: 9650/10000............. Loss: 0.5786\n",
      "Epoch: 9700/10000............. Loss: 0.5819\n",
      "Epoch: 9750/10000............. Loss: 0.5782\n",
      "Epoch: 9800/10000............. Loss: 0.5775\n",
      "Epoch: 9850/10000............. Loss: 0.5805\n",
      "Epoch: 9900/10000............. Loss: 0.5776\n",
      "Epoch: 9950/10000............. Loss: 0.5805\n",
      "Epoch: 10000/10000............. Loss: 0.5835\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from model.RNNEstimator import RNNEstimator\n",
    "\n",
    "loss_record = [] # Store loss after each epoch for visualization\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rnn_model = RNNEstimator(9, 12, 2, 9)\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train(rnn_model, dataloader, num_epochs, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RNN Loss Plot\n",
    "x = range(1, len(loss_record) + 1)\n",
    "y = loss_record\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"Average MAE Loss against Epoch for RNN Estimator\")\n",
    "plt.ylim(top=0.75)\n",
    "plt.savefig(\"img/RNN\" + \"_\" + str(num_epochs) +'.png') # Save diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RNN\n",
    "# torch.save(rnn_model.state_dict(), 'artefacts/rnn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate: Long short-term memory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# torch imports\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class LSTMEstimator(nn.Module):\n",
      "    \"\"\"\n",
      "    LSTM Estimator for generating sequences of target variables.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_features=9, hidden_dim=12, n_layers=2, output_dim=9, batch_size=12):\n",
      "        \"\"\"s\n",
      "        Initialize the model by setting up linear layers.\n",
      "        Use the input parameters to help define the layers of your model.\n",
      "        :param input_features: the number of input features in your training/test data\n",
      "        :param hidden_dim: helps define the number of nodes in the hidden layer(s)\n",
      "        :param output_dim: the number of outputs you want to produce\n",
      "        \"\"\"\n",
      "        super(LSTMEstimator, self).__init__()\n",
      "        \n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.hidden_layers = n_layers\n",
      "        self.batch_size = batch_size\n",
      "\n",
      "        # The LSTM takes track features as inputs, and outputs hidden states\n",
      "        # with dimensionality hidden_dim\n",
      "        self.lstm = nn.LSTM(input_features, self.hidden_dim, n_layers, dropout=0.3)\n",
      "        \n",
      "        self.hidden2target = nn.Linear(hidden_dim, output_dim)\n",
      "\n",
      "        \n",
      "    ## Initialize the hidden and cell states of the LSTM with zeros.\n",
      "    def init_hidden(self):\n",
      "        return (torch.zeros(self.hidden_layers, self.batch_size, self.hidden_dim)), \\\n",
      "               (torch.zeros(self.hidden_layers, self.batch_size, self.hidden_dim))\n",
      "        \n",
      "    \n",
      "    ## Define the feedforward behavior of the network\n",
      "    def forward(self, input, hidden_cell):\n",
      "        \"\"\"\n",
      "        Perform a forward pass of our model on input features, track.\n",
      "        :param input_track: A batch of input features of size (batch_size, input_features)\n",
      "        :return: A single, sigmoid-activated value as output\n",
      "        \"\"\"\n",
      "        \n",
      "        # define the feedforward behavior\n",
      "        lstm_out, hidden_cell = self.lstm(input.view(len(input), self.batch_size, -1), hidden_cell)\n",
      "\n",
      "        output = self.hidden2target(lstm_out)\n",
      "        \n",
      "        return output, hidden_cell\n"
     ]
    }
   ],
   "source": [
    "# Directory of LstmEstimator.py\n",
    "!pygmentize model/LstmEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch: 50/10000............. Loss: 0.6170\n",
      "Epoch: 100/10000............. Loss: 0.6065\n",
      "Epoch: 150/10000............. Loss: 0.5974\n",
      "Epoch: 200/10000............. Loss: 0.5944\n",
      "Epoch: 250/10000............. Loss: 0.5900\n",
      "Epoch: 300/10000............. Loss: 0.5876\n",
      "Epoch: 350/10000............. Loss: 0.5803\n",
      "Epoch: 400/10000............. Loss: 0.5768\n",
      "Epoch: 450/10000............. Loss: 0.5771\n",
      "Epoch: 500/10000............. Loss: 0.5763\n",
      "Epoch: 550/10000............. Loss: 0.5741\n",
      "Epoch: 600/10000............. Loss: 0.5730\n",
      "Epoch: 650/10000............. Loss: 0.5680\n",
      "Epoch: 700/10000............. Loss: 0.5613\n",
      "Epoch: 750/10000............. Loss: 0.5590\n",
      "Epoch: 800/10000............. Loss: 0.5650\n",
      "Epoch: 850/10000............. Loss: 0.5568\n",
      "Epoch: 900/10000............. Loss: 0.5571\n",
      "Epoch: 950/10000............. Loss: 0.5555\n",
      "Epoch: 1000/10000............. Loss: 0.5611\n",
      "Epoch: 1050/10000............. Loss: 0.5544\n",
      "Epoch: 1100/10000............. Loss: 0.5567\n",
      "Epoch: 1150/10000............. Loss: 0.5452\n",
      "Epoch: 1200/10000............. Loss: 0.5558\n",
      "Epoch: 1250/10000............. Loss: 0.5501\n",
      "Epoch: 1300/10000............. Loss: 0.5521\n",
      "Epoch: 1350/10000............. Loss: 0.5484\n",
      "Epoch: 1400/10000............. Loss: 0.5522\n",
      "Epoch: 1450/10000............. Loss: 0.5422\n",
      "Epoch: 1500/10000............. Loss: 0.5421\n",
      "Epoch: 1550/10000............. Loss: 0.5439\n",
      "Epoch: 1600/10000............. Loss: 0.5369\n",
      "Epoch: 1650/10000............. Loss: 0.5379\n",
      "Epoch: 1700/10000............. Loss: 0.5434\n",
      "Epoch: 1750/10000............. Loss: 0.5494\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from model.LSTMEstimator import LSTMEstimator\n",
    "\n",
    "loss_record = [] # Store loss after each epoch for visualization\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lstm_model = LSTMEstimator(9, 12, 2, 9)\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train(lstm_model, dataloader, num_epochs, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Loss Plot\n",
    "x = range(1, len(loss_record) + 1)\n",
    "y = loss_record\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"Average MAE Loss against Epoch for LSTM Estimator\")\n",
    "plt.ylim(top=0.75)\n",
    "plt.savefig(\"img/LSTM\" + \"_\" + str(num_epochs) +'.png') # Save diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LSTM\n",
    "# torch.save(lstm_model.state_dict(), 'artefacts/lstm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I setup a session using the Spotipy API then define the Playlist class for pooling together tracks, acquiring recommendations, and generating a playlist using one of the models trained above. When running the main function, a Playlist object is initialized and the constructor generates a playlist. The playlist is then posted to my Spotify profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "# Spotify for developers client auth variables\n",
    "username = os.environ['SPOTIFY_EMAIL']\n",
    "spotify_id = os.environ['SPOTIFY_ID']\n",
    "spotify_secret = os.environ['SPOTIFY_SECRET']\n",
    "\n",
    "# Set API scope\n",
    "scope='playlist-read-private, playlist-modify-private, playlist-modify-public'\n",
    "\n",
    "# Get auth token\n",
    "token = util.prompt_for_user_token(username, \n",
    "                                   scope,\n",
    "                                   client_id=spotify_id,\n",
    "                                   client_secret=spotify_secret,\n",
    "                                   redirect_uri='http://localhost/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "#Authenticate\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in WMW tracks to date for recommendations\n",
    "track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "track_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playlist Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playlist():\n",
    "    def __init__(self, wmw_pool, spotify_auth, spotify_token, model_type=\"LSTM\"):\n",
    "        \"\"\" Initiates pool of historic tracks, spotify api authentication and \n",
    "            model of choice.\n",
    "        \"\"\"\n",
    "        self.recommended_track_ids = pd.DataFrame() #list of track ids straight from spotify\n",
    "        self.trax = [] #all tracks as dict\n",
    "        self.df = None #this is where the data goes\n",
    "        self.playlist = None\n",
    "        self.wmw_pool_df = wmw_pool\n",
    "        self.token = spotify_token\n",
    "        self.spotify_auth = spotify_auth\n",
    "\n",
    "        # Feature set\n",
    "        self.feature_list =  ['danceability','energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                         'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "        # Setup feature standardisation\n",
    "        self.std_scaler = joblib.load('artefacts/standard_features.pkl')\n",
    "\n",
    "        # Setup dimensionality reduction for track picking\n",
    "        self.dim_red = joblib.load('artefacts/dim_red.pkl')\n",
    "\n",
    "        if model_type == \"LSTM\":\n",
    "            model = LstmEstimator(9, 30, 1, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/lstm_model.pth'))\n",
    "\n",
    "        elif model_type == \"RNN\":\n",
    "            model = RnnEstimator(9, 30, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/rnn_model.pth'))\n",
    "        else:\n",
    "            print(\"Please specify either the RNN or LSTM model using the model_type parameter.\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Start building the new playlist\n",
    "        self.intro_track = self.get_first_track()\n",
    "        self.new_playlist = self.predict_playlist(model, self.intro_track)\n",
    "\n",
    "\n",
    "    def get_first_track(self):\n",
    "        \"\"\"Get first track based on recommendations.\"\"\"\n",
    "        # Sample an intro song from the WMW history\n",
    "        song = self.wmw_pool_df[self.wmw_pool_df['position'] == 1].sample(1).copy()\n",
    "\n",
    "        # Gather a recommendation based on the intro track using spotify\n",
    "        song_res = self.spotify_auth.recommendations(seed_tracks=song['id'].values, limit=1)\n",
    "\n",
    "        # Gather track freatures from spotify result\n",
    "        for r in song_res['tracks']:\n",
    "            track = {'id': r['id'], 'artists': ([i['name'] for i in r['artists']],), 'name': r['name']}\n",
    "            track_features = self.spotify_auth.audio_features(r['id'])[0]\n",
    "            track.update(track_features)\n",
    "            self.intro_track = pd.DataFrame(track, index=[0])\n",
    "\n",
    "        # Prepare features\n",
    "        self.intro_track[self.feature_list] = self.std_scaler.transform(self.intro_track[self.feature_list])\n",
    "\n",
    "        return self.intro_track\n",
    "\n",
    "    def harmonic_match(self, key, mode):\n",
    "        \"\"\"Given a key and mode, return compatible keys according to the harmonic wheel.\"\"\"\n",
    "\n",
    "        # Harmonic Mixing Wheel: Pitch Class \n",
    "        # 1A 0 - A flat minor: 8 | 1B 0 - B major: 11\n",
    "        # 2A 1 - E flat minor: 3 | 2B 1 - F-sharp major: 6\n",
    "        # 3A 2 - B-flat minor: 10 | 3B 2 - D-flat major: 1\n",
    "        # 4A 3 - F minor: 5 | 4B 3 - A-flat major: 8\n",
    "        # 5A 4 - C minor: 0 | 5B 4 - E-flat major: 3\n",
    "        # 6A 5 - G minor: 7 | 6B 5 - B-flat major: 10\n",
    "        # 7A 6 - D minor: 2 | 7B 6 - F major: 5\n",
    "        # 8A 7 - A minor: 9 | 8B 7 - C major: 0\n",
    "        # 9A 8 - E minor: 4 | 9B 8 - G major: 7\n",
    "        # 10A 9 - B minor: 11 | 10B 9 - D major: 2\n",
    "        # 11A 10 - F sharp minor: 6 | 11B 10 - A major: 9\n",
    "        # 12A 11 - D flat minor: 1 | 12B 11 - E major: 4\n",
    "\n",
    "        # Harmonic keys mapped to corresponding pitch classes\n",
    "        pitch_to_harmonic_keys = {0: [4, 7], 1: [11, 2], 2: [6, 9],\n",
    "                                  3: [1, 4], 4: [8, 11], 5: [3, 6],\n",
    "                                  6: [10, 1], 7: [5, 8], 8: [0, 3],\n",
    "                                  9: [7, 10], 10: [2, 5], 11: [9, 0]}\n",
    "\n",
    "        # Extract values and keys\n",
    "        dv = np.array(list(pitch_to_harmonic_keys.values()))\n",
    "        dk = np.array(list(pitch_to_harmonic_keys.keys()))\n",
    "\n",
    "        # Harmonic key code corresponding song pitch class\n",
    "        harm_key = dv[np.where(dk == key)][0][mode]\n",
    "\n",
    "        # Harmonic key codes\n",
    "        harmonic_keys = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "\n",
    "        # Get compatible key codes\n",
    "        comp_keycodes = np.take(harmonic_keys,\n",
    "                                [harm_key - 1, harm_key, harm_key + 1],\n",
    "                                mode='wrap')\n",
    "\n",
    "        # Compatible keys\n",
    "        comp_keys = [np.where(dv[:, mode] == i)[0][0].tolist() for i in comp_keycodes]\n",
    "\n",
    "        # Compatible up/down key\n",
    "        inner_outer_key = np.array([np.where(dv[:, int(not bool(mode))] == harm_key)[0][0]])\n",
    "\n",
    "        comp_keys = np.concatenate([comp_keys, inner_outer_key])\n",
    "\n",
    "        return comp_keys, inner_outer_key\n",
    "\n",
    "    def get_position_recommendations(self, track_position):\n",
    "        \"\"\"Obtain a dataframe of recommended tracks for a specific track position.\"\"\"\n",
    "\n",
    "        recommendations = pd.DataFrame()\n",
    "\n",
    "        wmw_sample = random.sample(self.wmw_pool_df['volume'].unique().tolist(), 10)\n",
    "\n",
    "        wmw_sample_df = self.wmw_pool_df[\n",
    "            (self.wmw_pool_df['volume'].isin(wmw_sample)) &\n",
    "            (self.wmw_pool_df['position'] == track_position)\n",
    "        ]\n",
    "\n",
    "        # Iterate full catalog of WMW songs\n",
    "        for _, row in wmw_sample_df.iterrows():\n",
    "\n",
    "            song_search = row['track_name'].partition('-')[0] + ' ' + row['artist_name']\n",
    "            print(song_search)\n",
    "            try:\n",
    "                # Query Spotify to get track metadata then gather recommendations\n",
    "                # based on the sampled tracks from past volumes\n",
    "                song_res = self.spotify_auth.search(song_search, limit=1)['tracks']['items'][0]\n",
    "                results = self.spotify_auth.recommendations(seed_tracks=[song_res['id']], limit=20)\n",
    "\n",
    "                for r in results['tracks']:\n",
    "                    track = {'id': r['id'], 'artists': [i['name'] for i in r['artists']], 'name': r['name']}\n",
    "                    track_features = self.spotify_auth.audio_features(r['id'])[0]\n",
    "                    track.update(track_features)\n",
    "                    final_track = pd.DataFrame(track)\n",
    "                    recommendations = recommendations.append(final_track, ignore_index=True)\n",
    "            except:\n",
    "                print(\"Song not searchable\")\n",
    "\n",
    "        recommendations[self.feature_list] = self.std_scaler.transform(recommendations[self.feature_list])\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def pick_optimal_track(self, candidates, target):\n",
    "        \"\"\"Select the track with the minimum distance between the candidate tracks.\"\"\"\n",
    "\n",
    "        candidates_reduced = self.dim_red.transform(candidates[self.feature_list])\n",
    "\n",
    "        target_reduced = self.dim_red.transform(target)\n",
    "\n",
    "        next_track_id = np.argmin(cdist(target_reduced, candidates_reduced))\n",
    "\n",
    "        next_track = candidates.iloc[next_track_id]\n",
    "\n",
    "        return next_track\n",
    "\n",
    "\n",
    "    def predict_playlist(self, model, intro_track, playlist_len=15):\n",
    "        \"\"\"Predict playlist\"\"\"\n",
    "\n",
    "        # Prepare prediction list\n",
    "        predicted = intro_track\n",
    "\n",
    "        # Prepare initial input \n",
    "        inp = torch.FloatTensor(intro_track[self.feature_list].values)\n",
    "\n",
    "        print(\"Intro track:\", predicted['name'].values[0], '-', ', '.join(predicted['artists'].values[0]))\n",
    "\n",
    "        hidden_state = model.init_hidden()\n",
    "\n",
    "        for p in tqdm(range(2, playlist_len + 1)):\n",
    "            print(\"Track #%s - Generating candidates\" % p)\n",
    "\n",
    "            # Important stuff about the last track\n",
    "            current_track = predicted.iloc[-1]\n",
    "            current_key = current_track['key']\n",
    "            current_mode = current_track['mode']\n",
    "\n",
    "            # Generate output feature set of next song\n",
    "            output, hidden_state = model(inp, hidden_state)\n",
    "\n",
    "            output = output.detach().numpy()\n",
    "\n",
    "            # Get mode and key from last song and generate compatible keys and modes\n",
    "            keys, outer_inner_key = self.harmonic_match(current_key, current_mode)\n",
    "\n",
    "            # Get recommended tracks for current track position\n",
    "            recommendations = self.get_position_recommendations(p)\n",
    "\n",
    "#             print(\"Recommendations\", recommendations.shape)\n",
    "\n",
    "            # Filter for compatible tracks according to key and mode (harmonic wheel)\n",
    "            next_tracks_curr_mode = recommendations[\n",
    "                (recommendations['key'].isin(keys[:3])) & (recommendations['mode'] == current_mode)\n",
    "            ]\n",
    "\n",
    "#             print(\"Curr mode\", next_tracks_curr_mode.shape)\n",
    "\n",
    "            next_tracks_change_mode = recommendations[\n",
    "                (recommendations['key'] == keys[-1]) & (recommendations['mode'] == abs(int(not current_mode)))\n",
    "            ]\n",
    "\n",
    "#             print(\"Change mode\", next_tracks_change_mode.shape)\n",
    "\n",
    "            candidate_tracks = pd.concat([next_tracks_curr_mode, next_tracks_change_mode]).reset_index(drop=True)\n",
    "\n",
    "            # Ensure no duplicates exist in the playlist\n",
    "            candidate_tracks = candidate_tracks[~candidate_tracks['id'].isin(predicted['id'])]\n",
    "\n",
    "#             print(\"CANDIDATES:\", candidate_tracks.shape)\n",
    "\n",
    "            # Pick optimal track\n",
    "            next_track = self.pick_optimal_track(candidate_tracks, output)\n",
    "\n",
    "            print(\"Selected:\", next_track['name'], '-', ', '.join(next_track['artists']))\n",
    "\n",
    "            # Set new input vector for next song\n",
    "            inp = torch.FloatTensor([next_track[self.feature_list]])\n",
    "\n",
    "            # Append next song to playlist\n",
    "            predicted = predicted.append(next_track, ignore_index=True)\n",
    "\n",
    "            print('-' * 20)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "    def post_playlist(self):\n",
    "        if self.token:\n",
    "            spotify = spotipy.Spotify(auth=self.token)\n",
    "            spotify.trace = False\n",
    "            tracks = spotify.user_playlist_replace_tracks(\n",
    "                '1247785541', '7x1MY3AW3YCaHoicpiacGv',\n",
    "                self.new_playlist['id'].values\n",
    "            )\n",
    "            print(\"Posting latest Wilson's FM.\")\n",
    "        else:\n",
    "            print(\"Can't get token for\", username)\n",
    "\n",
    "def main():\n",
    "    # Spotify variables\n",
    "    username = config.SPOTIFY_EMAIL\n",
    "    spotify_id = config.SPOTIFY_ID\n",
    "    spotify_secret = config.SPOTIFY_SECRET\n",
    "\n",
    "    # Set API scope\n",
    "    scope = \"playlist-read-private, playlist-modify-private, playlist-modify-public\"\n",
    "\n",
    "    # Get auth token\n",
    "    token = util.prompt_for_user_token(username,\n",
    "                                       scope,\n",
    "                                       client_id=spotify_id,\n",
    "                                       client_secret=spotify_secret,\n",
    "                                       redirect_uri='http://localhost/'\n",
    "                                       )\n",
    "\n",
    "    # Authenticate\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager=SpotifyClientCredentials(\n",
    "            client_id=spotify_id,\n",
    "            client_secret=spotify_secret\n",
    "        )\n",
    "    )\n",
    "    data_dir = 'data'\n",
    "\n",
    "    track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "    playlist = Playlist(track_data, sp, token, model_type=\"LSTM\")\n",
    "\n",
    "    playlist.post_playlist()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed!')\n",
    "\n",
    "def test_harmonic_mixing(song):\n",
    "    \n",
    "    truth_octaves = [11, 0, 1]\n",
    "    \n",
    "    next_octaves = harmonic_match(0, 1)\n",
    "    \n",
    "    # check shape and equality of first track\n",
    "    assert len(truth_octaves) == len(next_octaves), \\\n",
    "        'Number of octaves incorrect, should get: ' + str(len(truth_octaves))    \n",
    "    \n",
    "    # check shape of input and output arrays\n",
    "    assert input_playlists[0][0].shape[1]==track_features_len, \\\n",
    "        'input_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    assert input_playlists[0][1].shape[1]==target_features_len, \\\n",
    "        'target_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    \n",
    "    #TODO: Add more tests\n",
    "    \n",
    "    _print_success_message()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_wmw",
   "language": "python",
   "name": "local_wmw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
