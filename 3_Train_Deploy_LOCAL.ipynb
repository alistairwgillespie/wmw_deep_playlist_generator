{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilson's Morning Wake Up Playlist Generator, Modeling and Learning\n",
    "\n",
    "## Local\n",
    "\n",
    "The following steps will be executed:\n",
    "\n",
    "* Upload your data to S3.\n",
    "* Define a benchmark and candidate models and training scripts\n",
    "* Train models and deploy.\n",
    "* Evaluate deployed estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PlaylistDataset\n",
    "\n",
    "dataset =  PlaylistDataset.PlaylistDataset(data_dir, \"tensor_train.csv\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "It's time to define and train the models!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Estimator\n",
    "\n",
    "## Define PyTorch estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of benchmark and candidate models and train components\n",
    "Here I will see if the configurations I have set work accordingly with no errors. Once it runs smoothly, I will instantiate an estimator using the Sagemaker API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for LSTM\n",
    "def train_lstm(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script of the LSTM model. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    criterion    - The loss function used for training. \n",
    "    optimizer    - The optimizer to use during training.\n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train() # Make sure that the model is in training mode.\n",
    "    \n",
    "    # training loop is provided\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cum_loss = 0\n",
    "            \n",
    "            hidden_cell = model.init_hidden()\n",
    "            \n",
    "            for i, track in enumerate(batch):\n",
    "                \n",
    "                track_x = track[0]\n",
    "                track_y = track[-1]\n",
    "                \n",
    "                output, hidden_cell = model(track_x.unsqueeze(0), hidden_cell)\n",
    "                \n",
    "                loss = criterion(output.squeeze(0), track_y)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                cum_loss += loss.data.item()\n",
    "\n",
    "            total_loss = cum_loss / len(batch[0])\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# torch imports\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class LstmEstimator(nn.Module):\n",
      "    \"\"\"\n",
      "    LSTM Estimator for generating sequential-based track target variables.\n",
      "    \"\"\"\n",
      "\n",
      "    ## Define the init function, the input params are required (for loading code in train.py to work)\n",
      "    def __init__(self, input_features=9, hidden_dim=30, n_layers=1, output_dim=9):\n",
      "        \"\"\"s\n",
      "        Initialize the model by setting up linear layers.\n",
      "        Use the input parameters to help define the layers of your model.\n",
      "        :param input_features: the number of input features in your training/test data\n",
      "        :param hidden_dim: helps define the number of nodes in the hidden layer(s)\n",
      "        :param output_dim: the number of outputs you want to produce\n",
      "        \"\"\"\n",
      "        super(LstmEstimator, self).__init__()\n",
      "        \n",
      "        self.hidden_layer_dim = hidden_dim\n",
      "        self.hidden_layers = n_layers\n",
      "        \n",
      "        # The LSTM takes track features as inputs, and outputs hidden states\n",
      "        # with dimensionality hidden_dim\n",
      "        self.lstm = nn.LSTM(input_features, hidden_dim, n_layers)\n",
      "        \n",
      "        self.hidden2target = nn.Linear(hidden_dim, output_dim)\n",
      "\n",
      "        \n",
      "    ## Initialize the hidden and cell states of the LSTM with zeros.\n",
      "    def init_hidden (self): \n",
      "        return (torch.zeros (self.hidden_layers, 1, self.hidden_layer_dim)),(torch.zeros (self.hidden_layers, 1, self.hidden_layer_dim))\n",
      "        \n",
      "    \n",
      "    ## Define the feedforward behavior of the network\n",
      "    def forward(self, input_sequence, hidden_cell):\n",
      "        \"\"\"\n",
      "        Perform a forward pass of our model on input features, x.\n",
      "        :param input_track: A batch of input features of size (batch_size, input_features)\n",
      "        :return: A single, sigmoid-activated value as output\n",
      "        \"\"\"\n",
      "        \n",
      "        # define the feedforward behavior\n",
      "        lstm_out, hidden_cell = self.lstm(input_sequence.view(len(input_sequence) ,1, -1), hidden_cell)\n",
      "        target_feat = self.hidden2target(lstm_out.view(len(input_sequence), -1))\n",
      "        \n",
      "        return target_feat, hidden_cell\n"
     ]
    }
   ],
   "source": [
    "# Directory of LstmEstimator.py\n",
    "!pygmentize model/LstmEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/1500............. Loss: 0.1122\n",
      "Epoch: 100/1500............. Loss: 0.0372\n",
      "Epoch: 150/1500............. Loss: 0.0124\n",
      "Epoch: 200/1500............. Loss: 0.0065\n",
      "Epoch: 250/1500............. Loss: 0.0057\n",
      "Epoch: 300/1500............. Loss: 0.0056\n",
      "Epoch: 350/1500............. Loss: 0.0105\n",
      "Epoch: 400/1500............. Loss: 0.0067\n",
      "Epoch: 450/1500............. Loss: 0.0103\n",
      "Epoch: 500/1500............. Loss: 0.0100\n",
      "Epoch: 550/1500............. Loss: 0.0063\n",
      "Epoch: 600/1500............. Loss: 0.0073\n",
      "Epoch: 650/1500............. Loss: 0.0064\n",
      "Epoch: 700/1500............. Loss: 0.0089\n",
      "Epoch: 750/1500............. Loss: 0.0083\n",
      "Epoch: 800/1500............. Loss: 0.0062\n",
      "Epoch: 850/1500............. Loss: 0.0080\n",
      "Epoch: 900/1500............. Loss: 0.0115\n",
      "Epoch: 950/1500............. Loss: 0.0123\n",
      "Epoch: 1000/1500............. Loss: 0.0098\n",
      "Epoch: 1050/1500............. Loss: 0.0078\n",
      "Epoch: 1100/1500............. Loss: 0.0078\n",
      "Epoch: 1150/1500............. Loss: 0.0077\n",
      "Epoch: 1200/1500............. Loss: 0.0075\n",
      "Epoch: 1250/1500............. Loss: 0.0077\n",
      "Epoch: 1300/1500............. Loss: 0.0093\n",
      "Epoch: 1350/1500............. Loss: 0.0082\n",
      "Epoch: 1400/1500............. Loss: 0.0061\n",
      "Epoch: 1450/1500............. Loss: 0.0085\n",
      "Epoch: 1500/1500............. Loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "from model.LstmEstimator import LstmEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lstm_model = LstmEstimator(9, 30, 1, 9)\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train_lstm(lstm_model, dataloader, 1500, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LSTM\n",
    "# torch.save(lstm_model.state_dict(), 'artefacts/lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for RNN\n",
    "def train_rnn(model, dataloader, epochs, criterion, optimizer, device):\n",
    "    \n",
    "    model.train() # Make sure that the model is in training mode.\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            \n",
    "            cum_loss = 0\n",
    "            \n",
    "            hidden = model.initHidden()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            for i, track in enumerate(batch):\n",
    "\n",
    "                track_x = track[0]\n",
    "                track_y = track[-1]\n",
    "                \n",
    "                output, hidden = model(track_x.unsqueeze(0), hidden)\n",
    "            \n",
    "                loss = criterion(output, track_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                cum_loss += loss.data.item()\n",
    "                \n",
    "            total_loss = cum_loss / len(batch[0])\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# torch imports\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class RnnEstimator(nn.Module):\n",
      "    \n",
      "    def __init__(self, input_size, hidden_size, output_size):\n",
      "        super(RnnEstimator, self).__init__()\n",
      "\n",
      "        self.hidden_size = hidden_size\n",
      "\n",
      "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
      "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
      "        \n",
      "    \n",
      "    ## Define the feedforward behavior of the network\n",
      "    def forward(self, input_sequence, hidden):\n",
      "        combined = torch.cat((input_sequence, hidden), 1)\n",
      "        hidden = self.i2h(combined)\n",
      "        output = self.i2o(combined)\n",
      "        return output, hidden\n",
      "    \n",
      "    def init_hidden(self):\n",
      "        return torch.zeros(1, self.hidden_size)\n"
     ]
    }
   ],
   "source": [
    "# Directory of RnnEstimator.py\n",
    "!pygmentize model/RnnEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from model.RnnEstimator import RnnEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rnn_model = RnnEstimator(9, 30, 9)\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train_rnn(rnn_model, dataloader, 1500, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RNN\n",
    "torch.save(model.state_dict(), 'artefacts/rnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "# Spotify for developers client auth variables\n",
    "username = os.environ['SPOTIFY_EMAIL']\n",
    "spotify_id = os.environ['SPOTIFY_ID']\n",
    "spotify_secret = os.environ['SPOTIFY_SECRET']\n",
    "\n",
    "# Set API scope\n",
    "scope='playlist-read-private, playlist-modify-private, playlist-modify-public'\n",
    "\n",
    "# Get auth token\n",
    "token = util.prompt_for_user_token(username, \n",
    "                                   scope,\n",
    "                                   client_id=spotify_id,\n",
    "                                   client_secret=spotify_secret,\n",
    "                                   redirect_uri='http://localhost/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "#Authenticate\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>position</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>Finding It There</td>\n",
       "      <td>Goldmund</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>123.707</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>spotify:track:6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6CnP...</td>\n",
       "      <td>220120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>Light Forms</td>\n",
       "      <td>Rohne</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>133.036</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>spotify:track:6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6MkUPsz5hYen...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6MkU...</td>\n",
       "      <td>265870</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>C-Side</td>\n",
       "      <td>Khruangbin</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.77900</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>94.073</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>spotify:track:6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6GvA...</td>\n",
       "      <td>283407</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Didn't I (Dave Allison Rework)</td>\n",
       "      <td>Darondo</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>186.033</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>spotify:track:1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1owjOeZt1BdY...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1owj...</td>\n",
       "      <td>328000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>Woman Of The Ghetto - Akshin Alizadeh Remix</td>\n",
       "      <td>Marlena Shaw</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>100.006</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>spotify:track:2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2h8c...</td>\n",
       "      <td>302467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume  position                                   track_name  \\\n",
       "0      38         1                             Finding It There   \n",
       "1      38         2                                  Light Forms   \n",
       "2      38         3                                       C-Side   \n",
       "3      38         4               Didn't I (Dave Allison Rework)   \n",
       "4      38         5  Woman Of The Ghetto - Akshin Alizadeh Remix   \n",
       "\n",
       "    artist_name  danceability   energy  key  loudness  mode  speechiness  ...  \\\n",
       "0      Goldmund         0.187  0.00257    1   -37.134     1       0.0427  ...   \n",
       "1         Rohne         0.671  0.54500   10   -12.848     0       0.0393  ...   \n",
       "2    Khruangbin         0.688  0.77900   11   -10.129     0       0.0579  ...   \n",
       "3       Darondo         0.539  0.70500    0    -6.729     1       0.0527  ...   \n",
       "4  Marlena Shaw         0.707  0.57300    7    -8.403     0       0.0276  ...   \n",
       "\n",
       "   liveness  valence    tempo            type                      id  \\\n",
       "0    0.0915   0.0374  123.707  audio_features  6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1    0.1180   0.2840  133.036  audio_features  6MkUPsz5hYeneo0a9H0VT8   \n",
       "2    0.3490   0.9380   94.073  audio_features  6GvAM8oyVApQHGMgpBt8yl   \n",
       "3    0.1330   0.6850  186.033  audio_features  1owjOeZt1BdYWW6T8fIAEe   \n",
       "4    0.0858   0.1890  100.006  audio_features  2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                    uri  \\\n",
       "0  spotify:track:6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1  spotify:track:6MkUPsz5hYeneo0a9H0VT8   \n",
       "2  spotify:track:6GvAM8oyVApQHGMgpBt8yl   \n",
       "3  spotify:track:1owjOeZt1BdYWW6T8fIAEe   \n",
       "4  spotify:track:2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...   \n",
       "1  https://api.spotify.com/v1/tracks/6MkUPsz5hYen...   \n",
       "2  https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...   \n",
       "3  https://api.spotify.com/v1/tracks/1owjOeZt1BdY...   \n",
       "4  https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...   \n",
       "\n",
       "                                        analysis_url duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/6CnP...      220120   \n",
       "1  https://api.spotify.com/v1/audio-analysis/6MkU...      265870   \n",
       "2  https://api.spotify.com/v1/audio-analysis/6GvA...      283407   \n",
       "3  https://api.spotify.com/v1/audio-analysis/1owj...      328000   \n",
       "4  https://api.spotify.com/v1/audio-analysis/2h8c...      302467   \n",
       "\n",
       "  time_signature  \n",
       "0              5  \n",
       "1              4  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in WMW tracks to date for recommendations\n",
    "track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "track_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_df[:,0], pca_df[:,1], pca_df[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pca.transform(track_data[feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import torch.optim as optim\n",
    "\n",
    "class Playlist():\n",
    "    def __init__(self, wmw_pool, model_type=\"LSTM\"):\n",
    "        self.recommended_track_ids = pd.DataFrame() #list of track ids straight from spotify\n",
    "        self.trax = [] #all tracks as dict\n",
    "        self.df = None #this is where the data goes\n",
    "        self.playlist = None\n",
    "        self.wmw_pool_df = wmw_pool\n",
    "        \n",
    "        # Feature set\n",
    "        self.feature_list =  ['danceability','energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                         'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    \n",
    "        # Setup feature standardisation\n",
    "        self.std_scaler = joblib.load('artefacts/standard_features.pkl')\n",
    "        \n",
    "        # Setup dimensionality reduction for track picking\n",
    "        self.dim_red = joblib.load('artefacts/dim_red.pkl')\n",
    "        \n",
    "        if model_type == \"LSTM\":\n",
    "            model = LSTMEstimator(9, 30, 1, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/lstm_model.pth'))\n",
    "            \n",
    "        elif model_type == \"RNN\":\n",
    "            model = RNNEstimator(9, 30, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/rnn_model.pth'))\n",
    "        else:\n",
    "            print(\"Please specify either the RNN or LSTM model using the model_type parameter.\")\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Start building the new playlist\n",
    "        self.intro_track = self.get_first_track()\n",
    "        self.new_playlist = self.predict_playlist(model, self.intro_track)\n",
    "\n",
    "    \n",
    "    def get_first_track(self):\n",
    "        \"\"\"Get first track based on recommendations.\"\"\"\n",
    "        # Sample an intro song from the WMW history\n",
    "        song = self.wmw_pool_df[self.wmw_pool_df['position'] == 1].sample(1).copy()\n",
    "\n",
    "        # Gather a recommendation based on the intro track using spotify\n",
    "        song_res = sp.recommendations(seed_tracks = song['id'].values, limit=1)\n",
    "        \n",
    "        # Gather track freatures from spotify result\n",
    "        for r in song_res['tracks']:\n",
    "            track={}\n",
    "            track['id'] = r['id']\n",
    "            track['artists'] = [i['name'] for i in r['artists']],\n",
    "            track['name'] = r['name']\n",
    "            track_features = sp.audio_features(r['id'])[0]\n",
    "            track.update(track_features)\n",
    "            self.intro_track = pd.DataFrame(track, index=[0])\n",
    "\n",
    "        # Prepare features\n",
    "        self.intro_track[self.feature_list] = self.std_scaler.transform(self.intro_track[self.feature_list])\n",
    "        \n",
    "        return self.intro_track\n",
    "    \n",
    "    def harmonic_match(self, key, mode):\n",
    "        \"\"\"Given a key and mode, return compatible keys according to the harmonic wheel.\"\"\"\n",
    "        \n",
    "        # Harmonic Mixing Wheel: Pitch Class \n",
    "        # 1A 0 - A flat minor: 8 | 1B 0 - B major: 11\n",
    "        # 2A 1 - E flat minor: 3 | 2B 1 - F-sharp major: 6\n",
    "        # 3A 2 - B-flat minor: 10 | 3B 2 - D-flat major: 1\n",
    "        # 4A 3 - F minor: 5 | 4B 3 - A-flat major: 8\n",
    "        # 5A 4 - C minor: 0 | 5B 4 - E-flat major: 3\n",
    "        # 6A 5 - G minor: 7 | 6B 5 - B-flat major: 10\n",
    "        # 7A 6 - D minor: 2 | 7B 6 - F major: 5\n",
    "        # 8A 7 - A minor: 9 | 8B 7 - C major: 0\n",
    "        # 9A 8 - E minor: 4 | 9B 8 - G major: 7\n",
    "        # 10A 9 - B minor: 11 | 10B 9 - D major: 2\n",
    "        # 11A 10 - F sharp minor: 6 | 11B 10 - A major: 9\n",
    "        # 12A 11 - D flat minor: 1 | 12B 11 - E major: 4\n",
    "\n",
    "        # Harmonic keys mapped to corresponding pitch classes\n",
    "        pitch_to_harmonic_keys = {0: [4, 7], 1: [11, 2], 2: [6, 9],\n",
    "                                  3: [1, 4], 4: [8, 11], 5: [3, 6],\n",
    "                                  6: [10, 1], 7: [5, 8], 8: [0, 3],\n",
    "                                  9: [7, 10], 10: [2, 5], 11: [9, 0]}\n",
    "\n",
    "        # Extract values and keys\n",
    "        dv = np.array(list(pitch_to_harmonic_keys.values()))\n",
    "        dk = np.array(list(pitch_to_harmonic_keys.keys()))\n",
    "\n",
    "        # Harmonic key code corresponding song pitch class\n",
    "        harm_key = dv[np.where(dk == key)][0][mode]\n",
    "\n",
    "        # Harmonic key codes\n",
    "        harmonic_keys = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "\n",
    "        # Get compatible key codes\n",
    "        comp_keycodes = np.take(harmonic_keys, \n",
    "                                [harm_key - 1, harm_key, harm_key + 1],\n",
    "                                mode='wrap')\n",
    "\n",
    "        # Compatible keys\n",
    "        comp_keys = [np.where(dv[:, mode] == i)[0][0].tolist() for i in comp_keycodes]\n",
    "\n",
    "        # Compatible up/down key\n",
    "        inner_outer_key = np.array([np.where(dv[:, int(not bool(mode))] == harm_key)[0][0]])\n",
    "\n",
    "        comp_keys = np.concatenate([comp_keys, inner_outer_key])\n",
    "        \n",
    "        return comp_keys, inner_outer_key\n",
    "    \n",
    "    \n",
    "    def get_position_recommendations(self, track_position):\n",
    "        \"\"\"Obtain a dataframe of recommended tracks for a specific track position.\"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame()\n",
    "\n",
    "        wmw_sample = random.sample(self.wmw_pool_df['volume'].unique().tolist(), 10)\n",
    "\n",
    "        wmw_sample_df = self.wmw_pool_df[\n",
    "            (self.wmw_pool_df['volume'].isin(wmw_sample)) & \n",
    "            (self.wmw_pool_df['position'] == track_position)\n",
    "        ]\n",
    "\n",
    "        # Iterate full catalog of WMW songs\n",
    "        for _, row in wmw_sample_df.iterrows():\n",
    "            \n",
    "            song_search = row['track_name'].partition('-')[0] + ' ' + row['artist_name']\n",
    "            \n",
    "            try:\n",
    "\n",
    "                # Query Spotify to get track metadata\n",
    "                song_res = sp.search(song_search, limit=1)['tracks']['items'][0]\n",
    "\n",
    "                # Gather recommendations for each of the past WMW tracks\n",
    "                results = sp.recommendations(seed_tracks = [song_res['id']], limit=20)\n",
    "\n",
    "                for r in results['tracks']:\n",
    "                    track={}\n",
    "                    track['id'] = r['id']\n",
    "                    track['artists'] = [i['name'] for i in r['artists']],\n",
    "                    track['name'] = r['name']\n",
    "                    track_features = sp.audio_features(r['id'])[0]\n",
    "                    track.update(track_features)\n",
    "                    final_track = pd.DataFrame(track, index=[0])\n",
    "                    recommendations = recommendations.append(final_track, ignore_index=True)\n",
    "\n",
    "            except:\n",
    "                print(\"Song not searchable\")\n",
    "\n",
    "        recommendations[self.feature_list] = self.std_scaler.transform(recommendations[self.feature_list])\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "    def pick_optimal_track(self, candidates, target):\n",
    "        \"\"\"Select the track with the minimum distance between the candidate tracks.\"\"\"\n",
    "        \n",
    "        candidates_reduced = self.dim_red.transform(candidates[self.feature_list])\n",
    "        \n",
    "        target_reduced = self.dim_red.transform(target)\n",
    "        \n",
    "        next_track_id = np.argmin(cdist(target_reduced, candidates_reduced))\n",
    "        \n",
    "        next_track = candidates.iloc[next_track_id]\n",
    "        \n",
    "        return next_track\n",
    "    \n",
    "\n",
    "    def predict_playlist(self, model, intro_track, playlist_len=15):\n",
    "        \"\"\"Predict playlist\"\"\"\n",
    "        \n",
    "        # Prepare prediction list\n",
    "        predicted = intro_track\n",
    "        \n",
    "        # Prepare initial input \n",
    "        inp = torch.FloatTensor(intro_track[self.feature_list].values)\n",
    "        \n",
    "        print(\"Intro track:\", predicted['name'].values[0], '-', ', '.join(predicted['artists'].values[0]))\n",
    "\n",
    "        for p in tqdm(range(2, playlist_len + 1)):\n",
    "            print(\"Track #%s - Generating candidates\" % p)\n",
    "            \n",
    "            # Important stuff about the last track\n",
    "            current_track = predicted.iloc[-1]\n",
    "            current_key = current_track['key']\n",
    "            current_mode = current_track['mode']\n",
    "\n",
    "            # Generate output feature set of next song\n",
    "            output = model(inp).detach().numpy()\n",
    "\n",
    "            # Get mode and key from last song and generate compatible keys and modes\n",
    "            keys, outer_inner_key = self.harmonic_match(current_key, current_mode)\n",
    "\n",
    "            # Get recommended tracks for current track position\n",
    "            recommendations = self.get_position_recommendations(p)\n",
    "            \n",
    "            print(\"Recommendations\", recommendations.shape)\n",
    "            \n",
    "            # Filter for compatible tracks according to key and mode (harmonic wheel)\n",
    "            next_tracks_curr_mode = recommendations[\n",
    "                (recommendations['key'].isin(keys[:3])) & (recommendations['mode'] == current_mode)\n",
    "            ]\n",
    "            \n",
    "            print(\"Curr mode\", next_tracks_curr_mode.shape)\n",
    "            \n",
    "            next_tracks_change_mode = recommendations[\n",
    "                (recommendations['key'] == keys[-1]) & (recommendations['mode'] == abs(int(not current_mode)))\n",
    "            ]\n",
    "            \n",
    "            print(\"Change mode\", next_tracks_change_mode.shape)\n",
    "            \n",
    "            candidate_tracks = pd.concat([next_tracks_curr_mode, next_tracks_change_mode]).reset_index(drop=True)\n",
    "            \n",
    "            # Ensure no duplicates exist in the playlist\n",
    "            candidate_tracks = candidate_tracks[~candidate_tracks['id'].isin(predicted['id'])]\n",
    "            \n",
    "            print(\"CANDIDATES:\", candidate_tracks.shape)\n",
    "            \n",
    "            # Pick optimal track\n",
    "            next_track = self.pick_optimal_track(candidate_tracks, output)\n",
    "            \n",
    "            print(\"Selected:\", next_track['name'], '-', ', '.join(next_track['artists']))\n",
    "\n",
    "            # Set new input vector for next song\n",
    "            inp = torch.FloatTensor([next_track[self.feature_list]])\n",
    "\n",
    "            # Append next song to playlist\n",
    "            predicted = predicted.append(next_track, ignore_index=True)\n",
    "            \n",
    "            print('-' * 20)\n",
    "\n",
    "        return predicted\n",
    "    \n",
    "\n",
    "    def post_playlist(self):\n",
    "        if token:\n",
    "            sp = spotipy.Spotify(auth=token)\n",
    "            sp.trace = False\n",
    "            tracks = sp.user_playlist_replace_tracks('1247785541', '7x1MY3AW3YCaHoicpiacGv', self.new_playlist['id'].values)\n",
    "            print(\"Posting latest Wilson's FM.\")\n",
    "        else:\n",
    "            print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed!')\n",
    "\n",
    "def test_harmonic_mixing(song):\n",
    "    \n",
    "    truth_octaves = [11, 0, 1]\n",
    "    \n",
    "    next_octaves = harmonic_match(0, 1)\n",
    "    \n",
    "    # check shape and equality of first track\n",
    "    assert len(truth_octaves) == len(next_octaves), \\\n",
    "        'Number of octaves incorrect, should get: ' + str(len(truth_octaves))    \n",
    "    \n",
    "    # check shape of input and output arrays\n",
    "    assert input_playlists[0][0].shape[1]==track_features_len, \\\n",
    "        'input_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    assert input_playlists[0][1].shape[1]==target_features_len, \\\n",
    "        'target_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    \n",
    "    #TODO: Add more tests\n",
    "    \n",
    "    _print_success_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl = Playlist(track_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.post_playlist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_wmw",
   "language": "python",
   "name": "local_wmw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
