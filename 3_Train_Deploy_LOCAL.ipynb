{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilson's Morning Wake Up Playlist Generator, Modeling and Learning\n",
    "\n",
    "## Local\n",
    "\n",
    "The following steps will be executed:\n",
    "\n",
    "* Upload your data to S3.\n",
    "* Define a benchmark and candidate models and training scripts\n",
    "* Train models and deploy.\n",
    "* Evaluate deployed estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import config\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PlaylistDataset\n",
    "\n",
    "dataset =  PlaylistDataset.PlaylistDataset(data_dir, \"tensor_train.csv\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "It's time to define and train the models!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Estimator\n",
    "\n",
    "## Define PyTorch estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of benchmark and candidate models and train components\n",
    "Here I will see if the configurations I have set work accordingly with no errors. Once it runs smoothly, I will instantiate the estimators using the Sagemaker API in the AWS notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the train function for training the baseline RNN model and candidate, LSTM model. Each model excepts a tensor of 9 features. For feed-forward behaviour, a single track - as input - along with with a hidden state is accepted, which is then used to predict the features of the following track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_record = [] # Store loss after each epoch for visualization\n",
    "\n",
    "# Training function for LSTM\n",
    "def train(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script of the LSTM model. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    criterion    - The loss function used for training. \n",
    "    optimizer    - The optimizer to use during training.\n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train() # Make sure that the model is in training mode.\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cum_loss = 0\n",
    "            \n",
    "            hidden_cell = model.init_hidden()\n",
    "            \n",
    "            for i, track in enumerate(batch):\n",
    "                \n",
    "                track_x = track[0]\n",
    "                track_y = track[-1]\n",
    "                \n",
    "                output, hidden_cell = model(track_x.unsqueeze(0), hidden_cell)\n",
    "                \n",
    "                loss = criterion(output.squeeze(0), track_y)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                cum_loss += loss.data.item()\n",
    "            \n",
    "            total_loss = cum_loss / len(batch[0])\n",
    "        \n",
    "        loss_record.append(total_loss)\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# torch imports\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class RNNEstimator(nn.Module):\n",
      "    \"\"\"\n",
      "    RNN Estimator for generating sequences of target variables.\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, input_features=9, hidden_dim=30, n_layers=1, output_dim=9):\n",
      "        super(RNNEstimator, self).__init__()\n",
      "\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.hidden_layers = n_layers\n",
      "        \n",
      "        # RNN Layer\n",
      "        self.rnn = nn.RNN(input_features, hidden_dim, n_layers, dropout=0.3)\n",
      "        \n",
      "        # Fully connected layer\n",
      "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
      "        \n",
      "    ## Initialize the hidden and cell states of the LSTM with zeros.\n",
      "    def init_hidden(self):\n",
      "        return torch.zeros(self.hidden_layers, 1, self.hidden_dim)\n",
      "        \n",
      "    ## Define the feedforward behavior of the network\n",
      "    def forward(self, input, hidden_state):\n",
      "        \n",
      "        # Passing in the input and hidden state into the model and obtaining outputs\n",
      "        output, hidden_state = self.rnn(input.view(len(input) ,1, -1), hidden_state)\n",
      "        \n",
      "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
      "        output = self.fc(output.contiguous().view(len(input), -1))\n",
      "        \n",
      "        return output, hidden_state\n"
     ]
    }
   ],
   "source": [
    "# Directory of RnnEstimator.py\n",
    "!pygmentize model/RNNEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch: 50/1500............. Loss: 0.1650\n",
      "Epoch: 100/1500............. Loss: 0.1201\n",
      "Epoch: 150/1500............. Loss: 0.1151\n",
      "Epoch: 200/1500............. Loss: 0.0763\n",
      "Epoch: 250/1500............. Loss: 0.0732\n",
      "Epoch: 300/1500............. Loss: 0.0449\n",
      "Epoch: 350/1500............. Loss: 0.0430\n",
      "Epoch: 400/1500............. Loss: 0.0286\n",
      "Epoch: 450/1500............. Loss: 0.0305\n",
      "Epoch: 500/1500............. Loss: 0.0841\n",
      "Epoch: 550/1500............. Loss: 0.0414\n",
      "Epoch: 600/1500............. Loss: 0.0457\n",
      "Epoch: 650/1500............. Loss: 0.0189\n",
      "Epoch: 700/1500............. Loss: 0.0233\n",
      "Epoch: 750/1500............. Loss: 0.0217\n",
      "Epoch: 800/1500............. Loss: 0.0233\n",
      "Epoch: 850/1500............. Loss: 0.0420\n",
      "Epoch: 900/1500............. Loss: 0.0384\n",
      "Epoch: 950/1500............. Loss: 0.0357\n",
      "Epoch: 1000/1500............. Loss: 0.0199\n",
      "Epoch: 1050/1500............. Loss: 0.0201\n",
      "Epoch: 1100/1500............. Loss: 0.0228\n",
      "Epoch: 1150/1500............. Loss: 0.0274\n",
      "Epoch: 1200/1500............. Loss: 0.0355\n",
      "Epoch: 1250/1500............. Loss: 0.0246\n",
      "Epoch: 1300/1500............. Loss: 0.0305\n",
      "Epoch: 1350/1500............. Loss: 0.0237\n",
      "Epoch: 1400/1500............. Loss: 0.0155\n",
      "Epoch: 1450/1500............. Loss: 0.0276\n",
      "Epoch: 1500/1500............. Loss: 0.0283\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from model.RNNEstimator import RNNEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rnn_model = RNNEstimator(9, 30, 2, 9)\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train(rnn_model, dataloader, 1500, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1500,) and (1900,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b834c27c5f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAE Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3358\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3359\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\local_wmw\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 242\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1500,) and (1900,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM Loss Plot\n",
    "x = range(1, 1500 + 1)\n",
    "y = loss_record\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"MAE Loss against Epoch for RNN Estimator\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RNN\n",
    "torch.save(rnn_model.state_dict(), 'artefacts/rnn_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate: Long short-term memory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of LstmEstimator.py\n",
    "!pygmentize model/LstmEstimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "from model.LSTMEstimator import LSTMEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lstm_model = LSTMEstimator(9, 30, 2, 9)\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train(lstm_model, dataloader, 1500, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Loss Plot\n",
    "x = range(1, 1500 + 1)\n",
    "y = loss_record\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"MAE Loss against Epoch for LSTM Estimator\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LSTM\n",
    "torch.save(lstm_model.state_dict(), 'artefacts/lstm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I setup a session using the Spotipy API. Then define a Playlist class for pooling together tracks, acquiring recommendations, and generating a playlist using one of the models trained above. When running the main function, a Playlist object is instatiated and the constructor generates a playlist. The playlist is then posted to my Spotify profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "# Spotify for developers client auth variables\n",
    "username = os.environ['SPOTIFY_EMAIL']\n",
    "spotify_id = os.environ['SPOTIFY_ID']\n",
    "spotify_secret = os.environ['SPOTIFY_SECRET']\n",
    "\n",
    "# Set API scope\n",
    "scope='playlist-read-private, playlist-modify-private, playlist-modify-public'\n",
    "\n",
    "# Get auth token\n",
    "token = util.prompt_for_user_token(username, \n",
    "                                   scope,\n",
    "                                   client_id=spotify_id,\n",
    "                                   client_secret=spotify_secret,\n",
    "                                   redirect_uri='http://localhost/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "#Authenticate\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>position</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>Finding It There</td>\n",
       "      <td>Goldmund</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>123.707</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>spotify:track:6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6CnP...</td>\n",
       "      <td>220120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>Light Forms</td>\n",
       "      <td>Rohne</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>133.036</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>spotify:track:6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6MkUPsz5hYen...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6MkU...</td>\n",
       "      <td>265870</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>C-Side</td>\n",
       "      <td>Khruangbin</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.77900</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>94.073</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>spotify:track:6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6GvA...</td>\n",
       "      <td>283407</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Didn't I (Dave Allison Rework)</td>\n",
       "      <td>Darondo</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>186.033</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>spotify:track:1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1owjOeZt1BdY...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1owj...</td>\n",
       "      <td>328000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>Woman Of The Ghetto - Akshin Alizadeh Remix</td>\n",
       "      <td>Marlena Shaw</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>100.006</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>spotify:track:2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2h8c...</td>\n",
       "      <td>302467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume  position                                   track_name  \\\n",
       "0      38         1                             Finding It There   \n",
       "1      38         2                                  Light Forms   \n",
       "2      38         3                                       C-Side   \n",
       "3      38         4               Didn't I (Dave Allison Rework)   \n",
       "4      38         5  Woman Of The Ghetto - Akshin Alizadeh Remix   \n",
       "\n",
       "    artist_name  danceability   energy  key  loudness  mode  speechiness  ...  \\\n",
       "0      Goldmund         0.187  0.00257    1   -37.134     1       0.0427  ...   \n",
       "1         Rohne         0.671  0.54500   10   -12.848     0       0.0393  ...   \n",
       "2    Khruangbin         0.688  0.77900   11   -10.129     0       0.0579  ...   \n",
       "3       Darondo         0.539  0.70500    0    -6.729     1       0.0527  ...   \n",
       "4  Marlena Shaw         0.707  0.57300    7    -8.403     0       0.0276  ...   \n",
       "\n",
       "   liveness  valence    tempo            type                      id  \\\n",
       "0    0.0915   0.0374  123.707  audio_features  6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1    0.1180   0.2840  133.036  audio_features  6MkUPsz5hYeneo0a9H0VT8   \n",
       "2    0.3490   0.9380   94.073  audio_features  6GvAM8oyVApQHGMgpBt8yl   \n",
       "3    0.1330   0.6850  186.033  audio_features  1owjOeZt1BdYWW6T8fIAEe   \n",
       "4    0.0858   0.1890  100.006  audio_features  2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                    uri  \\\n",
       "0  spotify:track:6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1  spotify:track:6MkUPsz5hYeneo0a9H0VT8   \n",
       "2  spotify:track:6GvAM8oyVApQHGMgpBt8yl   \n",
       "3  spotify:track:1owjOeZt1BdYWW6T8fIAEe   \n",
       "4  spotify:track:2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...   \n",
       "1  https://api.spotify.com/v1/tracks/6MkUPsz5hYen...   \n",
       "2  https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...   \n",
       "3  https://api.spotify.com/v1/tracks/1owjOeZt1BdY...   \n",
       "4  https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...   \n",
       "\n",
       "                                        analysis_url duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/6CnP...      220120   \n",
       "1  https://api.spotify.com/v1/audio-analysis/6MkU...      265870   \n",
       "2  https://api.spotify.com/v1/audio-analysis/6GvA...      283407   \n",
       "3  https://api.spotify.com/v1/audio-analysis/1owj...      328000   \n",
       "4  https://api.spotify.com/v1/audio-analysis/2h8c...      302467   \n",
       "\n",
       "  time_signature  \n",
       "0              5  \n",
       "1              4  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in WMW tracks to date for recommendations\n",
    "track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "track_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playlist():\n",
    "    def __init__(self, wmw_pool, spotify_auth, spotify_token, model_type=\"LSTM\"):\n",
    "        \"\"\" Initiates pool of historic tracks, spotify api authentication and \n",
    "            model of choice.\n",
    "        \"\"\"\n",
    "        self.recommended_track_ids = pd.DataFrame() #list of track ids straight from spotify\n",
    "        self.trax = [] #all tracks as dict\n",
    "        self.df = None #this is where the data goes\n",
    "        self.playlist = None\n",
    "        self.wmw_pool_df = wmw_pool\n",
    "        self.token = spotify_token\n",
    "        self.spotify_auth = spotify_auth\n",
    "\n",
    "        # Feature set\n",
    "        self.feature_list =  ['danceability','energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                         'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "        # Setup feature standardisation\n",
    "        self.std_scaler = joblib.load('artefacts/standard_features.pkl')\n",
    "\n",
    "        # Setup dimensionality reduction for track picking\n",
    "        self.dim_red = joblib.load('artefacts/dim_red.pkl')\n",
    "\n",
    "        if model_type == \"LSTM\":\n",
    "            model = LstmEstimator(9, 30, 1, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/lstm_model.pth'))\n",
    "\n",
    "        elif model_type == \"RNN\":\n",
    "            model = RnnEstimator(9, 30, 9)\n",
    "            model.load_state_dict(torch.load('artefacts/rnn_model.pth'))\n",
    "        else:\n",
    "            print(\"Please specify either the RNN or LSTM model using the model_type parameter.\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Start building the new playlist\n",
    "        self.intro_track = self.get_first_track()\n",
    "        self.new_playlist = self.predict_playlist(model, self.intro_track)\n",
    "\n",
    "\n",
    "    def get_first_track(self):\n",
    "        \"\"\"Get first track based on recommendations.\"\"\"\n",
    "        # Sample an intro song from the WMW history\n",
    "        song = self.wmw_pool_df[self.wmw_pool_df['position'] == 1].sample(1).copy()\n",
    "\n",
    "        # Gather a recommendation based on the intro track using spotify\n",
    "        song_res = self.spotify_auth.recommendations(seed_tracks=song['id'].values, limit=1)\n",
    "\n",
    "        # Gather track freatures from spotify result\n",
    "        for r in song_res['tracks']:\n",
    "            track = {'id': r['id'], 'artists': ([i['name'] for i in r['artists']],), 'name': r['name']}\n",
    "            track_features = self.spotify_auth.audio_features(r['id'])[0]\n",
    "            track.update(track_features)\n",
    "            self.intro_track = pd.DataFrame(track, index=[0])\n",
    "\n",
    "        # Prepare features\n",
    "        self.intro_track[self.feature_list] = self.std_scaler.transform(self.intro_track[self.feature_list])\n",
    "\n",
    "        return self.intro_track\n",
    "\n",
    "    def harmonic_match(self, key, mode):\n",
    "        \"\"\"Given a key and mode, return compatible keys according to the harmonic wheel.\"\"\"\n",
    "\n",
    "        # Harmonic Mixing Wheel: Pitch Class \n",
    "        # 1A 0 - A flat minor: 8 | 1B 0 - B major: 11\n",
    "        # 2A 1 - E flat minor: 3 | 2B 1 - F-sharp major: 6\n",
    "        # 3A 2 - B-flat minor: 10 | 3B 2 - D-flat major: 1\n",
    "        # 4A 3 - F minor: 5 | 4B 3 - A-flat major: 8\n",
    "        # 5A 4 - C minor: 0 | 5B 4 - E-flat major: 3\n",
    "        # 6A 5 - G minor: 7 | 6B 5 - B-flat major: 10\n",
    "        # 7A 6 - D minor: 2 | 7B 6 - F major: 5\n",
    "        # 8A 7 - A minor: 9 | 8B 7 - C major: 0\n",
    "        # 9A 8 - E minor: 4 | 9B 8 - G major: 7\n",
    "        # 10A 9 - B minor: 11 | 10B 9 - D major: 2\n",
    "        # 11A 10 - F sharp minor: 6 | 11B 10 - A major: 9\n",
    "        # 12A 11 - D flat minor: 1 | 12B 11 - E major: 4\n",
    "\n",
    "        # Harmonic keys mapped to corresponding pitch classes\n",
    "        pitch_to_harmonic_keys = {0: [4, 7], 1: [11, 2], 2: [6, 9],\n",
    "                                  3: [1, 4], 4: [8, 11], 5: [3, 6],\n",
    "                                  6: [10, 1], 7: [5, 8], 8: [0, 3],\n",
    "                                  9: [7, 10], 10: [2, 5], 11: [9, 0]}\n",
    "\n",
    "        # Extract values and keys\n",
    "        dv = np.array(list(pitch_to_harmonic_keys.values()))\n",
    "        dk = np.array(list(pitch_to_harmonic_keys.keys()))\n",
    "\n",
    "        # Harmonic key code corresponding song pitch class\n",
    "        harm_key = dv[np.where(dk == key)][0][mode]\n",
    "\n",
    "        # Harmonic key codes\n",
    "        harmonic_keys = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "\n",
    "        # Get compatible key codes\n",
    "        comp_keycodes = np.take(harmonic_keys,\n",
    "                                [harm_key - 1, harm_key, harm_key + 1],\n",
    "                                mode='wrap')\n",
    "\n",
    "        # Compatible keys\n",
    "        comp_keys = [np.where(dv[:, mode] == i)[0][0].tolist() for i in comp_keycodes]\n",
    "\n",
    "        # Compatible up/down key\n",
    "        inner_outer_key = np.array([np.where(dv[:, int(not bool(mode))] == harm_key)[0][0]])\n",
    "\n",
    "        comp_keys = np.concatenate([comp_keys, inner_outer_key])\n",
    "\n",
    "        return comp_keys, inner_outer_key\n",
    "\n",
    "    def get_position_recommendations(self, track_position):\n",
    "        \"\"\"Obtain a dataframe of recommended tracks for a specific track position.\"\"\"\n",
    "\n",
    "        recommendations = pd.DataFrame()\n",
    "\n",
    "        wmw_sample = random.sample(self.wmw_pool_df['volume'].unique().tolist(), 10)\n",
    "\n",
    "        wmw_sample_df = self.wmw_pool_df[\n",
    "            (self.wmw_pool_df['volume'].isin(wmw_sample)) &\n",
    "            (self.wmw_pool_df['position'] == track_position)\n",
    "        ]\n",
    "\n",
    "        # Iterate full catalog of WMW songs\n",
    "        for _, row in wmw_sample_df.iterrows():\n",
    "\n",
    "            song_search = row['track_name'].partition('-')[0] + ' ' + row['artist_name']\n",
    "            print(song_search)\n",
    "            try:\n",
    "                # Query Spotify to get track metadata then gather recommendations\n",
    "                # based on the sampled tracks from past volumes\n",
    "                song_res = self.spotify_auth.search(song_search, limit=1)['tracks']['items'][0]\n",
    "                results = self.spotify_auth.recommendations(seed_tracks=[song_res['id']], limit=20)\n",
    "\n",
    "                for r in results['tracks']:\n",
    "                    track = {'id': r['id'], 'artists': [i['name'] for i in r['artists']], 'name': r['name']}\n",
    "                    track_features = self.spotify_auth.audio_features(r['id'])[0]\n",
    "                    track.update(track_features)\n",
    "                    final_track = pd.DataFrame(track)\n",
    "                    recommendations = recommendations.append(final_track, ignore_index=True)\n",
    "            except:\n",
    "                print(\"Song not searchable\")\n",
    "\n",
    "        recommendations[self.feature_list] = self.std_scaler.transform(recommendations[self.feature_list])\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def pick_optimal_track(self, candidates, target):\n",
    "        \"\"\"Select the track with the minimum distance between the candidate tracks.\"\"\"\n",
    "\n",
    "        candidates_reduced = self.dim_red.transform(candidates[self.feature_list])\n",
    "\n",
    "        target_reduced = self.dim_red.transform(target)\n",
    "\n",
    "        next_track_id = np.argmin(cdist(target_reduced, candidates_reduced))\n",
    "\n",
    "        next_track = candidates.iloc[next_track_id]\n",
    "\n",
    "        return next_track\n",
    "\n",
    "\n",
    "    def predict_playlist(self, model, intro_track, playlist_len=15):\n",
    "        \"\"\"Predict playlist\"\"\"\n",
    "\n",
    "        # Prepare prediction list\n",
    "        predicted = intro_track\n",
    "\n",
    "        # Prepare initial input \n",
    "        inp = torch.FloatTensor(intro_track[self.feature_list].values)\n",
    "\n",
    "        print(\"Intro track:\", predicted['name'].values[0], '-', ', '.join(predicted['artists'].values[0]))\n",
    "\n",
    "        hidden_state = model.init_hidden()\n",
    "\n",
    "        for p in tqdm(range(2, playlist_len + 1)):\n",
    "            print(\"Track #%s - Generating candidates\" % p)\n",
    "\n",
    "            # Important stuff about the last track\n",
    "            current_track = predicted.iloc[-1]\n",
    "            current_key = current_track['key']\n",
    "            current_mode = current_track['mode']\n",
    "\n",
    "            # Generate output feature set of next song\n",
    "            output, hidden_state = model(inp, hidden_state)\n",
    "\n",
    "            output = output.detach().numpy()\n",
    "\n",
    "            # Get mode and key from last song and generate compatible keys and modes\n",
    "            keys, outer_inner_key = self.harmonic_match(current_key, current_mode)\n",
    "\n",
    "            # Get recommended tracks for current track position\n",
    "            recommendations = self.get_position_recommendations(p)\n",
    "\n",
    "#             print(\"Recommendations\", recommendations.shape)\n",
    "\n",
    "            # Filter for compatible tracks according to key and mode (harmonic wheel)\n",
    "            next_tracks_curr_mode = recommendations[\n",
    "                (recommendations['key'].isin(keys[:3])) & (recommendations['mode'] == current_mode)\n",
    "            ]\n",
    "\n",
    "#             print(\"Curr mode\", next_tracks_curr_mode.shape)\n",
    "\n",
    "            next_tracks_change_mode = recommendations[\n",
    "                (recommendations['key'] == keys[-1]) & (recommendations['mode'] == abs(int(not current_mode)))\n",
    "            ]\n",
    "\n",
    "#             print(\"Change mode\", next_tracks_change_mode.shape)\n",
    "\n",
    "            candidate_tracks = pd.concat([next_tracks_curr_mode, next_tracks_change_mode]).reset_index(drop=True)\n",
    "\n",
    "            # Ensure no duplicates exist in the playlist\n",
    "            candidate_tracks = candidate_tracks[~candidate_tracks['id'].isin(predicted['id'])]\n",
    "\n",
    "#             print(\"CANDIDATES:\", candidate_tracks.shape)\n",
    "\n",
    "            # Pick optimal track\n",
    "            next_track = self.pick_optimal_track(candidate_tracks, output)\n",
    "\n",
    "            print(\"Selected:\", next_track['name'], '-', ', '.join(next_track['artists']))\n",
    "\n",
    "            # Set new input vector for next song\n",
    "            inp = torch.FloatTensor([next_track[self.feature_list]])\n",
    "\n",
    "            # Append next song to playlist\n",
    "            predicted = predicted.append(next_track, ignore_index=True)\n",
    "\n",
    "            print('-' * 20)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "    def post_playlist(self):\n",
    "        if self.token:\n",
    "            spotify = spotipy.Spotify(auth=self.token)\n",
    "            spotify.trace = False\n",
    "            tracks = spotify.user_playlist_replace_tracks(\n",
    "                '1247785541', '7x1MY3AW3YCaHoicpiacGv',\n",
    "                self.new_playlist['id'].values\n",
    "            )\n",
    "            print(\"Posting latest Wilson's FM.\")\n",
    "        else:\n",
    "            print(\"Can't get token for\", username)\n",
    "\n",
    "def main():\n",
    "    # Spotify variables\n",
    "    username = config.SPOTIFY_EMAIL\n",
    "    spotify_id = config.SPOTIFY_ID\n",
    "    spotify_secret = config.SPOTIFY_SECRET\n",
    "\n",
    "    # Set API scope\n",
    "    scope = \"playlist-read-private, playlist-modify-private, playlist-modify-public\"\n",
    "\n",
    "    # Get auth token\n",
    "    token = util.prompt_for_user_token(username,\n",
    "                                       scope,\n",
    "                                       client_id=spotify_id,\n",
    "                                       client_secret=spotify_secret,\n",
    "                                       redirect_uri='http://localhost/'\n",
    "                                       )\n",
    "\n",
    "    # Authenticate\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager=SpotifyClientCredentials(\n",
    "            client_id=spotify_id,\n",
    "            client_secret=spotify_secret\n",
    "        )\n",
    "    )\n",
    "    data_dir = 'data'\n",
    "\n",
    "    track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "    playlist = Playlist(track_data, sp, token, model_type=\"LSTM\")\n",
    "\n",
    "    playlist.post_playlist()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed!')\n",
    "\n",
    "def test_harmonic_mixing(song):\n",
    "    \n",
    "    truth_octaves = [11, 0, 1]\n",
    "    \n",
    "    next_octaves = harmonic_match(0, 1)\n",
    "    \n",
    "    # check shape and equality of first track\n",
    "    assert len(truth_octaves) == len(next_octaves), \\\n",
    "        'Number of octaves incorrect, should get: ' + str(len(truth_octaves))    \n",
    "    \n",
    "    # check shape of input and output arrays\n",
    "    assert input_playlists[0][0].shape[1]==track_features_len, \\\n",
    "        'input_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    assert input_playlists[0][1].shape[1]==target_features_len, \\\n",
    "        'target_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    \n",
    "    #TODO: Add more tests\n",
    "    \n",
    "    _print_success_message()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_wmw",
   "language": "python",
   "name": "local_wmw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
