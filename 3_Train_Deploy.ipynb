{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilson's Morning Wake Up Playlist Generator, Modeling and Learning\n",
    "\n",
    "The following steps will be executed:\n",
    "\n",
    "* Upload your data to S3.\n",
    "* Define a benchmark and candidate models and training scripts\n",
    "* Train models and deploy.\n",
    "* Evaluate deployed estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 456\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user   4096 Mar 18 23:10 .\r\n",
      "drwxrwxr-x 8 ec2-user ec2-user   4096 Mar 19 04:06 ..\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  28467 Mar  4 23:01 test.csv\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 165699 Mar 19 00:12 train.csv\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  90194 Mar 19 00:12 wmw.csv\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 166951 Mar 18 23:35 wmw_tracks.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your training data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'sagemaker/wmw_estimator'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "It's time to define and train the models!\n",
    "\n",
    "---\n",
    "\n",
    "## Complete a training script \n",
    "\n",
    "To implement a custom estimator, I need to complete a `train.py` script. \n",
    "\n",
    "A typical training script:\n",
    "* Loads training data from a specified directory\n",
    "* Parses any training & model hyperparameters (ex. nodes in a neural network, training epochs, etc.)\n",
    "* Instantiates a model of your design, with any specified hyperparams\n",
    "* Trains that model \n",
    "* Finally, saves the model so that it can be hosted/deployed, later\n",
    "\n",
    "### Defining and training a model\n",
    "\n",
    "To complete a `train.py` file, you will:\n",
    "1. Import any extra libraries you need\n",
    "2. Define any additional model training hyperparameters using `parser.add_argument`\n",
    "2. Define a model in the `if __name__ == '__main__':` section\n",
    "3. Train the model in that same section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: 'model/train.py'\r\n"
     ]
    }
   ],
   "source": [
    "# Directory of train.py\n",
    "!pygmentize model/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an Estimator\n",
    "\n",
    "When a custom model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained; the `train.py` function you specified above. To run a custom training script in SageMaker, construct an estimator, and fill in the appropriate constructor arguments:\n",
    "\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training and prediction.\n",
    "* **source_dir**: The path to the training script directory `source_sklearn` OR `source_pytorch`.\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training and prediction.\n",
    "* **source_dir**: The path to the training script directory `train_sklearn` OR `train_pytorch`.\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training.\n",
    "* **source_dir**: The path to the training script directory `train_sklearn` OR `train_pytorch`.\n",
    "* **role**: Role ARN, which was specified, above.\n",
    "* **train_instance_count**: The number of training instances (should be left at 1).\n",
    "* **train_instance_type**: The type of SageMaker instance for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* **sagemaker_session**: The session used to train on Sagemaker.\n",
    "* **hyperparameters** (optional): A dictionary `{'name':value, ..}` passed to the train function as hyperparameters.\n",
    "\n",
    "Note: For a PyTorch model, there is another optional argument **framework_version**, which you can set to the latest version of PyTorch, `1.0`.\n",
    "\n",
    "## Define PyTorch estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences and targets\n",
    "def create_playlist_sequences(input_data):\n",
    "    input_playlists = []\n",
    "    \n",
    "    for i in input_data['volume'].unique():\n",
    "        temp_vol = input_data[input_data['volume'] == i]\n",
    "        X = temp_vol.iloc[:, 2:10].values\n",
    "        y = temp_vol.iloc[:, 10:].values\n",
    "        input_playlists.append((X, y))\n",
    "        \n",
    "    return input_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed!')\n",
    "\n",
    "def test_playlist_sequences(input_playlists):\n",
    "    \n",
    "    track_features = [-2.39099487, -2.63509459, -0.27732204,  0.92969533, -0.48983686,-1.15691947,  1.08569029, -1.20454903,  2.09618458, -5.37044178, 0.23380331]\n",
    "    \n",
    "    track_features_len = 11\n",
    "    target_features_len = 8\n",
    "    \n",
    "    # check shape and equality of first track\n",
    "    assert len(input_playlists[0][0][0]) == len(track_features), \\\n",
    "        'Number of features in input_playlist features does not match expected number of ' + str(len(track_features))    \n",
    "    \n",
    "    # check shape of input and output arrays\n",
    "    assert input_playlists[0][0].shape[1]==track_features_len, \\\n",
    "        'input_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    assert input_playlists[0][1].shape[1]==target_features_len, \\\n",
    "        'target_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    \n",
    "    #TODO: Add more tests\n",
    "    \n",
    "    _print_success_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of benchmark and candidate models and train components\n",
    "Here I will see if the configurations I have set work accordingly with no errors. Once it runs smoothly, I will instantiate an estimator using the Sagemaker API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "\n",
    "# Gather sequences and targets\n",
    "processed_data = create_playlist_sequences(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for LSTM\n",
    "def train_lstm(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script of the LSTM model. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    criterion    - The loss function used for training. \n",
    "    optimizer    - The optimizer to use during training.\n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    \n",
    "    # training loop is provided\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        model.train() # Make sure that the model is in training mode.\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            # get data\n",
    "            batch_x, batch_y = batch\n",
    "            \n",
    "            # \n",
    "            batch_x = torch.from_numpy(batch_x).float().squeeze()\n",
    "            batch_y = torch.from_numpy(batch_y).float()\n",
    "\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_dim),\n",
    "                torch.zeros(1, 1, model.hidden_layer_dim))\n",
    "\n",
    "            # get predictions from model\n",
    "            y_pred = model(batch_x)\n",
    "            \n",
    "            # perform backprop\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "            \n",
    "        if epoch%25 == 1:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.672984648395229\n",
      "Epoch: 26, Loss: 0.5712427996300362\n",
      "Epoch: 51, Loss: 0.5238120588096412\n",
      "Epoch: 76, Loss: 0.4796866669848159\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from model.LSTM_Estimator import LSTMEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMEstimator(8, 30, 1, 8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train_lstm(model, processed_data, 100, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPOTIFY_EMAIL=gillaw06@gmail.com\n"
     ]
    }
   ],
   "source": [
    "%env SPOTIFY_EMAIL=gillaw06@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPOTIFY_ID=ce1d1ca394724265951a48a0deea6d01\n"
     ]
    }
   ],
   "source": [
    "%env SPOTIFY_ID=ce1d1ca394724265951a48a0deea6d01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPOTIFY_SECRET=3ce5bb4c8c18423f9e8b3f12db963e31\n"
     ]
    }
   ],
   "source": [
    "%env SPOTIFY_SECRET=3ce5bb4c8c18423f9e8b3f12db963e31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/39/8efecac5a29cb7092788c11e6dff46087bfe716663ce7b85fd7d34e85c6e/spotipy-2.10.0-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spotipy) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spotipy) (2.20.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->spotipy) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->spotipy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->spotipy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.20.0->spotipy) (1.23)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: spotipy\n",
      "Successfully installed spotipy-2.10.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "# Defaults\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Spotify for developers client auth variables\n",
    "username = os.environ['SPOTIFY_EMAIL']\n",
    "spotify_id = os.environ['SPOTIFY_ID']\n",
    "spotify_secret = os.environ['SPOTIFY_SECRET']\n",
    "\n",
    "# Set API scope\n",
    "scope='playlist-read-private'\n",
    "\n",
    "# Get auth token\n",
    "token = util.prompt_for_user_token(username, \n",
    "                                   scope,\n",
    "                                   client_id=spotify_id,\n",
    "                                   client_secret=spotify_secret,\n",
    "                                   redirect_uri='http://localhost/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Authenticate\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>position</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>Finding It There</td>\n",
       "      <td>Goldmund</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>123.707</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>spotify:track:6CnPCuUcM3A5PMP4gUy0vw</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6CnP...</td>\n",
       "      <td>220120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>Light Forms</td>\n",
       "      <td>Rohne</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>133.036</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>spotify:track:6MkUPsz5hYeneo0a9H0VT8</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6MkUPsz5hYen...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6MkU...</td>\n",
       "      <td>265870</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>C-Side</td>\n",
       "      <td>Khruangbin</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.77900</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>94.073</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>spotify:track:6GvAM8oyVApQHGMgpBt8yl</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6GvA...</td>\n",
       "      <td>283407</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Didn't I (Dave Allison Rework)</td>\n",
       "      <td>Darondo</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>186.033</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>spotify:track:1owjOeZt1BdYWW6T8fIAEe</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1owjOeZt1BdY...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1owj...</td>\n",
       "      <td>328000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>Woman Of The Ghetto - Akshin Alizadeh Remix</td>\n",
       "      <td>Marlena Shaw</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>100.006</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>spotify:track:2h8cQH7zhUWrynZi2MKhhC</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2h8c...</td>\n",
       "      <td>302467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume  position                                   track_name  \\\n",
       "0      38         1                             Finding It There   \n",
       "1      38         2                                  Light Forms   \n",
       "2      38         3                                       C-Side   \n",
       "3      38         4               Didn't I (Dave Allison Rework)   \n",
       "4      38         5  Woman Of The Ghetto - Akshin Alizadeh Remix   \n",
       "\n",
       "    artist_name  danceability   energy  key  loudness  mode  speechiness  ...  \\\n",
       "0      Goldmund         0.187  0.00257    1   -37.134     1       0.0427  ...   \n",
       "1         Rohne         0.671  0.54500   10   -12.848     0       0.0393  ...   \n",
       "2    Khruangbin         0.688  0.77900   11   -10.129     0       0.0579  ...   \n",
       "3       Darondo         0.539  0.70500    0    -6.729     1       0.0527  ...   \n",
       "4  Marlena Shaw         0.707  0.57300    7    -8.403     0       0.0276  ...   \n",
       "\n",
       "   liveness  valence    tempo            type                      id  \\\n",
       "0    0.0915   0.0374  123.707  audio_features  6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1    0.1180   0.2840  133.036  audio_features  6MkUPsz5hYeneo0a9H0VT8   \n",
       "2    0.3490   0.9380   94.073  audio_features  6GvAM8oyVApQHGMgpBt8yl   \n",
       "3    0.1330   0.6850  186.033  audio_features  1owjOeZt1BdYWW6T8fIAEe   \n",
       "4    0.0858   0.1890  100.006  audio_features  2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                    uri  \\\n",
       "0  spotify:track:6CnPCuUcM3A5PMP4gUy0vw   \n",
       "1  spotify:track:6MkUPsz5hYeneo0a9H0VT8   \n",
       "2  spotify:track:6GvAM8oyVApQHGMgpBt8yl   \n",
       "3  spotify:track:1owjOeZt1BdYWW6T8fIAEe   \n",
       "4  spotify:track:2h8cQH7zhUWrynZi2MKhhC   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/6CnPCuUcM3A5...   \n",
       "1  https://api.spotify.com/v1/tracks/6MkUPsz5hYen...   \n",
       "2  https://api.spotify.com/v1/tracks/6GvAM8oyVApQ...   \n",
       "3  https://api.spotify.com/v1/tracks/1owjOeZt1BdY...   \n",
       "4  https://api.spotify.com/v1/tracks/2h8cQH7zhUWr...   \n",
       "\n",
       "                                        analysis_url duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/6CnP...      220120   \n",
       "1  https://api.spotify.com/v1/audio-analysis/6MkU...      265870   \n",
       "2  https://api.spotify.com/v1/audio-analysis/6GvA...      283407   \n",
       "3  https://api.spotify.com/v1/audio-analysis/1owj...      328000   \n",
       "4  https://api.spotify.com/v1/audio-analysis/2h8c...      302467   \n",
       "\n",
       "  time_signature  \n",
       "0              5  \n",
       "1              4  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in WMW tracks to date for recommendations\n",
    "track_data = pd.read_csv(os.path.join(data_dir, \"wmw_tracks.csv\"))\n",
    "\n",
    "track_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "feature_list =  ['danceability','energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                 'instrumentalness', 'liveness', 'valence']\n",
    "\n",
    "#'mode','key','tempo'\n",
    "\n",
    "std_scaler = joblib.load('standard_features.pkl')\n",
    "\n",
    "class Playlist():\n",
    "    def __init__(self):\n",
    "        self.name = \"Wilson's Morning Wake Up Vol. Test\"\n",
    "        self.intro_songs = []\n",
    "        self.search_results = []\n",
    "        self.recommended_track_ids = pd.DataFrame() #list of track ids straight from spotify\n",
    "        self.trax = [] #all tracks as dict\n",
    "        self.df = None #this is where the data goes\n",
    "        self.playlist = None\n",
    "        \n",
    "       \n",
    "        # DO EVERYTHING\n",
    "        self.get_recommendations() # Grab recommendations based on full WMW catalog\n",
    "        self.prep_features() # Prepare features using StandardScaler\n",
    "#         self.get_predictions() # Generate features for each track position for new WMW\n",
    "        \n",
    "        \n",
    "    def get_recommendations(self):\n",
    "        print('Getting Recommendations...')\n",
    "        \n",
    "        # Iterate full catalog of WMW songs\n",
    "        for _, row in tqdm(track_data[track_data['volume'] == 38].iterrows(), total=track_data[track_data['volume'] == 38].shape[0]):\n",
    "            song_search = row['track_name'].partition('-')[0] + ' ' + row['artist_name']\n",
    "            try:\n",
    "        \n",
    "                # Query Spotify to get track metadata\n",
    "                song_res = sp.search(song_search, limit=1)['tracks']['items'][0]\n",
    "\n",
    "                self.search_results.append({\n",
    "                    'id': song_res['id'],\n",
    "                    'artists': [i['name'] for i in song_res['artists']],\n",
    "                    'name': song_res['name']\n",
    "                })\n",
    "                \n",
    "                # Gather recommendations for each of the past WMW tracks\n",
    "                results = sp.recommendations(seed_tracks = [song_res['id']], limit=10)\n",
    "\n",
    "                for r in results['tracks']:\n",
    "                    track={}\n",
    "                    track['id'] = r['id']\n",
    "                    track['artists'] = [i['name'] for i in r['artists']],\n",
    "                    track['name'] = r['name']\n",
    "                    track_features = sp.audio_features(r['id'])[0]\n",
    "                    track.update(track_features)\n",
    "                    final_track = pd.DataFrame(track, index=[0])\n",
    "                    self.recommended_track_ids = self.recommended_track_ids.append(final_track, ignore_index=True)\n",
    "                    \n",
    "            except:\n",
    "                print(\"Song not searchable\")\n",
    "        \n",
    "        return self.recommended_track_ids\n",
    "    \n",
    "    \n",
    "    def prep_features(self):\n",
    "        self.recommended_track_ids[feature_list] = std_scaler.transform(self.recommended_track_ids[feature_list])\n",
    "            \n",
    "    \n",
    "    def generate_playlist_features(model, intro_tracks, predict_len=15):\n",
    "        hidden = model.init_hidden()\n",
    "        \n",
    "        # extracts features from intro tracks\n",
    "        intro_input = text_to_tensor()\n",
    "        \n",
    "        # predicted playlist\n",
    "        predicted = intro_tracks\n",
    "        \n",
    "        # build up hidden state\n",
    "        for p in range(len(intro_tracks) - 1):\n",
    "            _, hidden = model(intro_input[p], hidden)\n",
    "        inp = intro_input[-1]\n",
    "        \n",
    "        for p in range(predict_len):\n",
    "            output, hidden = model(inp, hidden)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Recommendations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b9a14b7d3c4ef7a4a76c7fceda32b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:63: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (150,11) (8,) (150,11) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c3c263198080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaylist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-79daec0b69e2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# DO EVERYTHING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Grab recommendations based on full WMW catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Prepare features using StandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#         self.get_predictions() # Generate features for each track position for new WMW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-79daec0b69e2>\u001b[0m in \u001b[0;36mprep_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprep_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommended_track_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommended_track_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (150,11) (8,) (150,11) "
     ]
    }
   ],
   "source": [
    "pl = Playlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.recommended_track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b04e1ac0814432b87502a8469e4687e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song not searchable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "recommended = pd.DataFrame()\n",
    "\n",
    "# Iterate full catalog of WMW songs\n",
    "for _, row in tqdm(track_data[track_data['volume'] == random.randint(1, 38)].iterrows(), total=track_data[track_data['volume'] == 38].shape[0]):\n",
    "    song_search = row['track_name'].partition('-')[0] + ' ' + row['artist_name']\n",
    "    try:\n",
    "\n",
    "        # Query Spotify to get track metadata\n",
    "        song_res = sp.search(song_search, limit=1)['tracks']['items'][0]\n",
    "\n",
    "        # Gather recommendations for each of the past WMW tracks\n",
    "        results = sp.recommendations(seed_tracks = [song_res['id']], limit=10)\n",
    "\n",
    "        for r in results['tracks']:\n",
    "            track={}\n",
    "            track['id'] = r['id']\n",
    "            track['artists'] = [i['name'] for i in r['artists']],\n",
    "            track['name'] = r['name']\n",
    "            track_features = sp.audio_features(r['id'])[0]\n",
    "            track.update(track_features)\n",
    "            final_track = pd.DataFrame(track, index=[0])\n",
    "            recommended = recommended.append(final_track, ignore_index=True)\n",
    "\n",
    "    except:\n",
    "        print(\"Song not searchable\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended[feature_list] = std_scaler.transform(recommended[feature_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.270634</td>\n",
       "      <td>-1.953245</td>\n",
       "      <td>-1.698487</td>\n",
       "      <td>-0.413963</td>\n",
       "      <td>2.101379</td>\n",
       "      <td>0.880142</td>\n",
       "      <td>-0.370022</td>\n",
       "      <td>-1.045094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.283823</td>\n",
       "      <td>-1.430230</td>\n",
       "      <td>-0.480783</td>\n",
       "      <td>-0.382700</td>\n",
       "      <td>1.758053</td>\n",
       "      <td>0.824983</td>\n",
       "      <td>-0.309774</td>\n",
       "      <td>-0.814932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.267029</td>\n",
       "      <td>-2.509883</td>\n",
       "      <td>-3.175392</td>\n",
       "      <td>-0.391632</td>\n",
       "      <td>2.149991</td>\n",
       "      <td>0.813371</td>\n",
       "      <td>-0.759378</td>\n",
       "      <td>-1.079364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.158680</td>\n",
       "      <td>-2.319823</td>\n",
       "      <td>-1.377730</td>\n",
       "      <td>-0.041034</td>\n",
       "      <td>2.128723</td>\n",
       "      <td>0.778533</td>\n",
       "      <td>-0.528928</td>\n",
       "      <td>-0.836087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.656877</td>\n",
       "      <td>-1.934566</td>\n",
       "      <td>-1.145537</td>\n",
       "      <td>-0.313473</td>\n",
       "      <td>2.098340</td>\n",
       "      <td>0.830789</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>-0.857242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness  speechiness  acousticness  \\\n",
       "0     -1.270634 -1.953245 -1.698487    -0.413963      2.101379   \n",
       "1     -2.283823 -1.430230 -0.480783    -0.382700      1.758053   \n",
       "2     -2.267029 -2.509883 -3.175392    -0.391632      2.149991   \n",
       "3     -1.158680 -2.319823 -1.377730    -0.041034      2.128723   \n",
       "4     -1.656877 -1.934566 -1.145537    -0.313473      2.098340   \n",
       "\n",
       "   instrumentalness  liveness   valence  \n",
       "0          0.880142 -0.370022 -1.045094  \n",
       "1          0.824983 -0.309774 -0.814932  \n",
       "2          0.813371 -0.759378 -1.079364  \n",
       "3          0.778533 -0.528928 -0.836087  \n",
       "4          0.830789 -0.339898 -0.857242  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended[feature_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song = [ 0.0609,  1.0491,  0.5765, -0.3122, -0.6526,  0.0296, -0.7938,  0.0199]\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# np.argmin(cdist([song], recommended[feature_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                             4Zwo8D1koSzLJCYd5NlX81\n",
       "artists                                                       [Tycho]\n",
       "name                                                     Outer Sunset\n",
       "danceability                                                 0.526236\n",
       "energy                                                       0.545087\n",
       "key                                                                 8\n",
       "loudness                                                   -0.0348222\n",
       "mode                                                                1\n",
       "speechiness                                                 -0.235315\n",
       "acousticness                                                 0.691617\n",
       "instrumentalness                                             0.824983\n",
       "liveness                                                    -0.473198\n",
       "valence                                                       1.59245\n",
       "tempo                                                          96.994\n",
       "type                                                   audio_features\n",
       "uri                              spotify:track:4Zwo8D1koSzLJCYd5NlX81\n",
       "track_href          https://api.spotify.com/v1/tracks/4Zwo8D1koSzL...\n",
       "analysis_url        https://api.spotify.com/v1/audio-analysis/4Zwo...\n",
       "duration_ms                                                    250384\n",
       "time_signature                                                      4\n",
       "Name: 142, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended.iloc[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "feature_list =  ['danceability','energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                 'instrumentalness', 'liveness', 'valence']\n",
    "\n",
    "std_scaler = joblib.load('standard_features.pkl')\n",
    "\n",
    "def predict_playlist(model, initial_songs=[], predict_len=15):\n",
    "    global recommended\n",
    "    intro_tracks = pd.DataFrame() #list of track ids straight from spotify\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate full catalog of WMW songs\n",
    "    for song in tqdm(initial_songs, total=len(initial_songs)):\n",
    "                \n",
    "        song_search = song\n",
    "                \n",
    "        try:\n",
    "            \n",
    "            # Query Spotify to get track metadata\n",
    "            song_res = sp.search(song_search, limit=1)['tracks']['items'][0]\n",
    "            \n",
    "            track = {\n",
    "                'id': song_res['id'],\n",
    "                'artists': [i['name'] for i in song_res['artists']],\n",
    "                'name': song_res['name']\n",
    "            }\n",
    "            \n",
    "            track_features = sp.audio_features(track['id'])[0]\n",
    "            \n",
    "            track.update(track_features)\n",
    "            \n",
    "            final_track = pd.DataFrame(track, index=[0])\n",
    "            \n",
    "            intro_tracks = intro_tracks.append(final_track, ignore_index=True)\n",
    "                \n",
    "        except:\n",
    "            print(\"Song not searchable\")\n",
    "\n",
    "    intro_tracks[feature_list] = std_scaler.transform(intro_tracks[feature_list])\n",
    "            \n",
    "    predicted = intro_tracks\n",
    "\n",
    "    inp = torch.FloatTensor(intro_tracks[feature_list].values)\n",
    "    \n",
    "    print(\"Intro\", inp)\n",
    "\n",
    "    sample = recommended.copy()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        output = model(inp).detach().numpy()\n",
    "        next_song_id = np.argmin(cdist(output, sample[feature_list]))\n",
    "        next_song = sample.iloc[next_song_id].copy()\n",
    "        inp = torch.FloatTensor([next_song[feature_list]])\n",
    "        print(\"New song\", next_song['artists'], next_song['name'])\n",
    "        predicted = predicted.append(next_song, ignore_index=True)\n",
    "        sample = sample.drop([next_song_id], axis=0).reset_index(drop=True)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_match(key, mode):\n",
    "    \n",
    "    key = key\n",
    "    mode = mode\n",
    "        \n",
    "    # Harmonic Mixing Wheel: Pitch Class \n",
    "    # 1A - A flat minor: 8\n",
    "    # 1B - B major: 11\n",
    "    # 2A - E flat minor: 3\n",
    "    # 2B - F-sharp major: 6\n",
    "    # 3A - B-flat minor: 10\n",
    "    # 3B - D-flat major: 1\n",
    "    # 4A - F minor: 5\n",
    "    # 4B - A-flat major: 8\n",
    "    # 5A - C minor: 0\n",
    "    # 5B - E-flat major: 3\n",
    "    # 6A - G minor: 7\n",
    "    # 6B - B-flat major: 10\n",
    "    # 7A - D minor: 2\n",
    "    # 7B - F major: 5\n",
    "    # 8A - A minor: 9\n",
    "    # 8B - C major: 0\n",
    "    # 9A - E minor: 4\n",
    "    # 9B - G major: 7\n",
    "    # 10A - B minor: 11\n",
    "    # 10B - D major: 2\n",
    "    # 11A - F sharp minor: 6\n",
    "    # 11B - A major: 9\n",
    "    # 12A - D flat minor: 1\n",
    "    # 12B - E major: 4\n",
    "\n",
    "    \n",
    "#     harmonic_wheel_to_pitch = {8:0, 3:1, 10:2, \n",
    "#                                5:3, 0:4, 7:5, \n",
    "#                                2:6, 9:7, 4:8,\n",
    "#                                11:9,6:10, 1:11}\n",
    "    \n",
    "        \n",
    "    pitch_to_harmonic_wheel = {0: [8, 11] 1: [3, 6], 2: [10, 1], \n",
    "                               3: [5, 8], 4: [0, 3], 5: [7, 10], \n",
    "                               6: [2, 5], 7: [9, 0], 8: [4, 7],\n",
    "                               9: [11, 2],10: [6, 9],11: [1, 4]}\n",
    "    \n",
    "    pitch_to_harmonic_wheel[key] = \n",
    "    \n",
    "    # Harmonic Wheel: \n",
    "    # http://www.harmonic-mixing.com/Images/camelotHarmonicMixing.jpg\n",
    "    harmonic_wheel = [[0 , 1 , 2, 3, 4, 0],\n",
    "                      [1 , 1 , 2, 3, 4, 4],\n",
    "                      [12, 12, 0, 0, 5, 5],\n",
    "                      [11, 11, 0, 0, 6, 6],\n",
    "                      [10, 10, 9, 8, 7, 7],\n",
    "                      [0 , 10, 9, 8, 7, 0]]\n",
    "    \n",
    "    harmonic_wheel = np.array(harmonic_wheel)\n",
    "    \n",
    "    # Extract values and keys\n",
    "    dv = np.array(list(pitch_to_harmonic_wheel.values()))\n",
    "    dk = np.array(list(pitch_to_harmonic_wheel.keys()))\n",
    "\n",
    "    # Harmonic octave\n",
    "    harmonic_octave = dv[np.where(dk == key)][0][mode]\n",
    "    print(\"Harmonic octave: \", harmonic_octave)\n",
    "    \n",
    "    rows = np.where(harmonic_octave == harmonic_wheel)[0]\n",
    "    cols = np.where(harmonic_octave == harmonic_wheel)[1]\n",
    "\n",
    "    zip(rows, cols):\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_to_harmonic_wheel = {0: [8, 11], 1: [3, 6],  2: [10, 1], \n",
    "                           3: [5, 8],  4: [0, 3],  5: [7, 10], \n",
    "                           6: [2, 5],  7: [9, 0],  8: [4, 7],\n",
    "                           9: [11, 2], 10: [6, 9], 11: [1, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_wheel = [[1, 0 , 2, 3, 0, 4],\n",
    "                  [0 , 1 , 2, 3, 4, 0],\n",
    "                  [12, 12, 0, 0, 5, 5],\n",
    "                  [11, 11, 0, 0, 6, 6],\n",
    "                  [0, 10, 9, 8, 7, 0],\n",
    "                  [10 , 0, 9, 8, 0, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values and keys\n",
    "dv = np.array(list(pitch_to_harmonic_wheel.values()))\n",
    "dk = np.array(list(pitch_to_harmonic_wheel.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8, 11],\n",
       "       [ 3,  6],\n",
       "       [10,  1],\n",
       "       [ 5,  8],\n",
       "       [ 0,  3],\n",
       "       [ 7, 10],\n",
       "       [ 2,  5],\n",
       "       [ 9,  0],\n",
       "       [ 4,  7],\n",
       "       [11,  2],\n",
       "       [ 6,  9],\n",
       "       [ 1,  4]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic octave:  4\n"
     ]
    }
   ],
   "source": [
    "# Key = 8, Mode = 0\n",
    "key = 8\n",
    "mode = 0\n",
    "\n",
    "# Harmonic octave\n",
    "harmonic_octave = dv[np.where(dk == key)][0][mode]\n",
    "print(\"Harmonic octave: \", harmonic_octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonic_wheel = np.array(harmonic_wheel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  2,  3,  0,  4],\n",
       "       [ 0,  1,  2,  3,  4,  0],\n",
       "       [12, 12,  0,  0,  5,  5],\n",
       "       [11, 11,  0,  0,  6,  6],\n",
       "       [ 0, 10,  9,  8,  7,  0],\n",
       "       [10,  0,  9,  8,  0,  7]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 4]\n",
      " [3 4 0]]\n"
     ]
    }
   ],
   "source": [
    "x, y = 1, 4\n",
    "\n",
    "print(harmonic_wheel[x-1:x+1, y-1:y+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 3 Column: 5\n",
      "\n",
      "Neighbours:\n",
      " [[3 4 0]\n",
      " [0 5 5]\n",
      " [0 6 6]]\n",
      "\n",
      "Uniques: \n",
      " {0, 3, 4, 5, 6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# row, column\n",
    "x, y = 2, 4\n",
    "print(\"Row:\", x + 1, \"Column:\", y + 1)\n",
    "print()\n",
    "print(\"Neighbours:\\n\", harmonic_wheel[x-1:x+2, y-1:y+2])\n",
    "print()\n",
    "print(\"Uniques: \\n\", set(harmonic_wheel[x-1:x+2, y-1:y+2].ravel()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([5, 4]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(harmonic_octave == harmonic_wheel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-4ca894a8f7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mharmonic_octave\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mharmonic_wheel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "np.where(harmonic_octave == harmonic_wheel).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.where(harmonic_octave == harmonic_wheel)[0]\n",
    "cols = np.where(harmonic_octave == harmonic_wheel)[1]\n",
    "\n",
    "a, b = zip(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 5), (1, 4))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch\n",
    "\n",
    "def _print_success_message():\n",
    "    print('Tests Passed!')\n",
    "\n",
    "def test_harmonic_mixing(song):\n",
    "    \n",
    "    truth_octaves = []\n",
    "    \n",
    "    next_octaves = harmonic_match(8, 1)\n",
    "    \n",
    "    # check shape and equality of first track\n",
    "    assert len(truth_octaves) == len(next_octaves), \\\n",
    "        'Number of octaves incorrect, should get: ' + str(len(truth_octaves))    \n",
    "    \n",
    "    # check shape of input and output arrays\n",
    "    assert input_playlists[0][0].shape[1]==track_features_len, \\\n",
    "        'input_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    assert input_playlists[0][1].shape[1]==target_features_len, \\\n",
    "        'target_features should have as many columns as selected features, got: {}'.format(train_x.shape[1])\n",
    "    \n",
    "    #TODO: Add more tests\n",
    "    \n",
    "    _print_success_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1581d650edf34d42bbc7afbdd97a6b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intro tensor([[-1.7968, -2.6588, -4.1506, -0.4095,  2.1287,  0.7989, -0.4152, -0.9601]])\n",
      "New song ['Zola Blood'] Good Love\n",
      "New song ['Oliver Schories'] Brizzle\n",
      "New song ['Tycho'] Coastal Brake\n",
      "New song ['DJ Koze'] Pick Up\n",
      "New song ['Maribou State'] Rituals\n",
      "New song ['Vessels'] Elliptic\n",
      "New song ['Caribou'] Sun\n",
      "New song ['Equador', 'Sieren'] Avalon - Sieren Remix\n",
      "New song ['Com Truise'] Silicon Tare\n",
      "New song ['Tall Ships'] Day by Day\n",
      "New song ['Kidnap'] Vehl\n",
      "New song ['Chon'] Book\n",
      "New song ['DAVID AUGUST'] Epikur - Original\n",
      "New song ['Enrico Sangiuliano'] Astral Projection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artists</th>\n",
       "      <th>name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3oRuCzqdduzZ2CBhAtv8zO</td>\n",
       "      <td>Luke Howard</td>\n",
       "      <td>Portrait Gallery</td>\n",
       "      <td>-1.796820</td>\n",
       "      <td>-2.658849</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.150644</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.409497</td>\n",
       "      <td>2.128723</td>\n",
       "      <td>0.798855</td>\n",
       "      <td>-0.415209</td>\n",
       "      <td>-0.960053</td>\n",
       "      <td>127.536</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:3oRuCzqdduzZ2CBhAtv8zO</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3oRuCzqdduzZ...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3oRu...</td>\n",
       "      <td>367667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0vbbQvmRs38P27DCSctZ7L</td>\n",
       "      <td>[Zola Blood]</td>\n",
       "      <td>Good Love</td>\n",
       "      <td>0.246349</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>4</td>\n",
       "      <td>0.449872</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.527852</td>\n",
       "      <td>0.077884</td>\n",
       "      <td>-0.098201</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>0.073558</td>\n",
       "      <td>95.005</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0vbbQvmRs38P27DCSctZ7L</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0vbbQvmRs38P...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0vbb...</td>\n",
       "      <td>225613</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3GPYUPEP8O4cMn7mLA9RX1</td>\n",
       "      <td>[Oliver Schories]</td>\n",
       "      <td>Brizzle</td>\n",
       "      <td>0.873295</td>\n",
       "      <td>-0.118022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269368</td>\n",
       "      <td>-0.705384</td>\n",
       "      <td>0.909173</td>\n",
       "      <td>-0.513866</td>\n",
       "      <td>-0.087216</td>\n",
       "      <td>123.015</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:3GPYUPEP8O4cMn7mLA9RX1</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3GPYUPEP8O4c...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3GPY...</td>\n",
       "      <td>489000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0dE9ro91KUtV5Xi7bDPy6b</td>\n",
       "      <td>[Tycho]</td>\n",
       "      <td>Coastal Brake</td>\n",
       "      <td>-0.134296</td>\n",
       "      <td>1.096121</td>\n",
       "      <td>9</td>\n",
       "      <td>0.292425</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282210</td>\n",
       "      <td>-0.338360</td>\n",
       "      <td>1.007878</td>\n",
       "      <td>-0.362491</td>\n",
       "      <td>0.272411</td>\n",
       "      <td>120.008</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0dE9ro91KUtV5Xi7bDPy6b</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0dE9ro91KUtV...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0dE9...</td>\n",
       "      <td>334129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5YzBL3vkQnp3JbeDRRSbSQ</td>\n",
       "      <td>[DJ Koze]</td>\n",
       "      <td>Pick Up</td>\n",
       "      <td>0.503845</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.421189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146547</td>\n",
       "      <td>-0.870026</td>\n",
       "      <td>0.494030</td>\n",
       "      <td>-0.436296</td>\n",
       "      <td>0.830891</td>\n",
       "      <td>124.912</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:5YzBL3vkQnp3JbeDRRSbSQ</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5YzBL3vkQnp3...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5YzB...</td>\n",
       "      <td>398151</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0UCU2uiUBfToI9EDdrS6aJ</td>\n",
       "      <td>[Maribou State]</td>\n",
       "      <td>Rituals</td>\n",
       "      <td>0.515040</td>\n",
       "      <td>-0.136701</td>\n",
       "      <td>10</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105794</td>\n",
       "      <td>-0.588714</td>\n",
       "      <td>-0.002399</td>\n",
       "      <td>-0.362491</td>\n",
       "      <td>0.272411</td>\n",
       "      <td>121.012</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0UCU2uiUBfToI9EDdrS6aJ</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0UCU2uiUBfTo...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0UCU...</td>\n",
       "      <td>266839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3qQ6Y9vTezy0CZAi9QObvj</td>\n",
       "      <td>[Vessels]</td>\n",
       "      <td>Elliptic</td>\n",
       "      <td>-0.610103</td>\n",
       "      <td>0.404994</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.114593</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.509987</td>\n",
       "      <td>-0.597829</td>\n",
       "      <td>0.795952</td>\n",
       "      <td>-0.211870</td>\n",
       "      <td>-0.070293</td>\n",
       "      <td>123.013</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:3qQ6Y9vTezy0CZAi9QObvj</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3qQ6Y9vTezy0...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3qQ6...</td>\n",
       "      <td>528593</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0c7V10APHbimDgQppV8dFz</td>\n",
       "      <td>[Caribou]</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0.380695</td>\n",
       "      <td>1.152159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755136</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.389399</td>\n",
       "      <td>-0.747920</td>\n",
       "      <td>0.508546</td>\n",
       "      <td>0.119496</td>\n",
       "      <td>0.564344</td>\n",
       "      <td>127.983</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0c7V10APHbimDgQppV8dFz</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0c7V10APHbim...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0c7V...</td>\n",
       "      <td>344920</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1Oym7AEESwzeCjaFvFT4OC</td>\n",
       "      <td>[Equador, Sieren]</td>\n",
       "      <td>Avalon - Sieren Remix</td>\n",
       "      <td>-0.352607</td>\n",
       "      <td>0.787916</td>\n",
       "      <td>6</td>\n",
       "      <td>1.001775</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.554649</td>\n",
       "      <td>-0.819624</td>\n",
       "      <td>0.505642</td>\n",
       "      <td>-0.423493</td>\n",
       "      <td>-0.925782</td>\n",
       "      <td>133.072</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:1Oym7AEESwzeCjaFvFT4OC</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1Oym7AEESwze...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1Oym...</td>\n",
       "      <td>290526</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05vajmV6LbINFD5fGBS9my</td>\n",
       "      <td>[Com Truise]</td>\n",
       "      <td>Silicon Tare</td>\n",
       "      <td>-0.554125</td>\n",
       "      <td>0.848623</td>\n",
       "      <td>9</td>\n",
       "      <td>0.914467</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.469791</td>\n",
       "      <td>-0.450777</td>\n",
       "      <td>0.290813</td>\n",
       "      <td>-0.279650</td>\n",
       "      <td>0.289335</td>\n",
       "      <td>176.208</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:05vajmV6LbINFD5fGBS9my</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/05vajmV6LbIN...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/05va...</td>\n",
       "      <td>242709</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2lnplRF8NCYfdyKqaJNCG0</td>\n",
       "      <td>[Tall Ships]</td>\n",
       "      <td>Day by Day</td>\n",
       "      <td>-0.643689</td>\n",
       "      <td>1.259564</td>\n",
       "      <td>9</td>\n",
       "      <td>0.930589</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266578</td>\n",
       "      <td>-0.870042</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>-0.504828</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>100.026</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:2lnplRF8NCYfdyKqaJNCG0</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2lnplRF8NCYf...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2lnp...</td>\n",
       "      <td>360246</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6TecGli3dA4NMIdH6C9K4m</td>\n",
       "      <td>[Kidnap]</td>\n",
       "      <td>Vehl</td>\n",
       "      <td>-0.632493</td>\n",
       "      <td>0.820604</td>\n",
       "      <td>5</td>\n",
       "      <td>1.094736</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.427362</td>\n",
       "      <td>-0.761896</td>\n",
       "      <td>-0.562697</td>\n",
       "      <td>-0.515372</td>\n",
       "      <td>-0.523000</td>\n",
       "      <td>129.929</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:6TecGli3dA4NMIdH6C9K4m</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6TecGli3dA4N...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6Tec...</td>\n",
       "      <td>301645</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0zCbXOPent461dbCEBRQwM</td>\n",
       "      <td>[Chon]</td>\n",
       "      <td>Book</td>\n",
       "      <td>-0.083916</td>\n",
       "      <td>1.077442</td>\n",
       "      <td>6</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.601544</td>\n",
       "      <td>-0.798660</td>\n",
       "      <td>0.639185</td>\n",
       "      <td>0.021593</td>\n",
       "      <td>0.653193</td>\n",
       "      <td>114.990</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0zCbXOPent461dbCEBRQwM</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0zCbXOPent46...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0zCb...</td>\n",
       "      <td>162444</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5XxFY11r0YA6Xoyh1O9WsR</td>\n",
       "      <td>[DAVID AUGUST]</td>\n",
       "      <td>Epikur - Original</td>\n",
       "      <td>-0.369400</td>\n",
       "      <td>0.092119</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027075</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.543483</td>\n",
       "      <td>-0.832992</td>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.850009</td>\n",
       "      <td>-0.738776</td>\n",
       "      <td>117.989</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:5XxFY11r0YA6Xoyh1O9WsR</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5XxFY11r0YA6...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5XxF...</td>\n",
       "      <td>490725</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32nw9Qc5rYjsPWGLy14Yh5</td>\n",
       "      <td>[Enrico Sangiuliano]</td>\n",
       "      <td>Astral Projection</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.745888</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115283</td>\n",
       "      <td>-0.814763</td>\n",
       "      <td>0.897560</td>\n",
       "      <td>-0.347429</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>124.981</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:32nw9Qc5rYjsPWGLy14Yh5</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/32nw9Qc5rYjs...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/32nw...</td>\n",
       "      <td>483960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id               artists                   name  \\\n",
       "0   3oRuCzqdduzZ2CBhAtv8zO           Luke Howard       Portrait Gallery   \n",
       "1   0vbbQvmRs38P27DCSctZ7L          [Zola Blood]              Good Love   \n",
       "2   3GPYUPEP8O4cMn7mLA9RX1     [Oliver Schories]                Brizzle   \n",
       "3   0dE9ro91KUtV5Xi7bDPy6b               [Tycho]          Coastal Brake   \n",
       "4   5YzBL3vkQnp3JbeDRRSbSQ             [DJ Koze]                Pick Up   \n",
       "5   0UCU2uiUBfToI9EDdrS6aJ       [Maribou State]                Rituals   \n",
       "6   3qQ6Y9vTezy0CZAi9QObvj             [Vessels]               Elliptic   \n",
       "7   0c7V10APHbimDgQppV8dFz             [Caribou]                    Sun   \n",
       "8   1Oym7AEESwzeCjaFvFT4OC     [Equador, Sieren]  Avalon - Sieren Remix   \n",
       "9   05vajmV6LbINFD5fGBS9my          [Com Truise]           Silicon Tare   \n",
       "10  2lnplRF8NCYfdyKqaJNCG0          [Tall Ships]             Day by Day   \n",
       "11  6TecGli3dA4NMIdH6C9K4m              [Kidnap]                   Vehl   \n",
       "12  0zCbXOPent461dbCEBRQwM                [Chon]                   Book   \n",
       "13  5XxFY11r0YA6Xoyh1O9WsR        [DAVID AUGUST]      Epikur - Original   \n",
       "14  32nw9Qc5rYjsPWGLy14Yh5  [Enrico Sangiuliano]      Astral Projection   \n",
       "\n",
       "    danceability    energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0      -1.796820 -2.658849    1 -4.150644     1    -0.409497      2.128723   \n",
       "1       0.246349 -0.019956    4  0.449872     0    -0.527852      0.077884   \n",
       "2       0.873295 -0.118022    0  0.229195     1     0.269368     -0.705384   \n",
       "3      -0.134296  1.096121    9  0.292425     1    -0.282210     -0.338360   \n",
       "4       0.503845  0.106128    5  0.421189     1     0.146547     -0.870026   \n",
       "5       0.515040 -0.136701   10  0.428307     0    -0.105794     -0.588714   \n",
       "6      -0.610103  0.404994   10 -0.114593     0    -0.509987     -0.597829   \n",
       "7       0.380695  1.152159    1  0.755136     1    -0.389399     -0.747920   \n",
       "8      -0.352607  0.787916    6  1.001775     0    -0.554649     -0.819624   \n",
       "9      -0.554125  0.848623    9  0.914467     0    -0.469791     -0.450777   \n",
       "10     -0.643689  1.259564    9  0.930589     1    -0.266578     -0.870042   \n",
       "11     -0.632493  0.820604    5  1.094736     0    -0.427362     -0.761896   \n",
       "12     -0.083916  1.077442    6  0.895833     1    -0.601544     -0.798660   \n",
       "13     -0.369400  0.092119    1 -0.027075     1    -0.543483     -0.832992   \n",
       "14      0.985249  0.745888    6  0.549114     0     0.115283     -0.814763   \n",
       "\n",
       "    instrumentalness  liveness   valence    tempo            type  \\\n",
       "0           0.798855 -0.415209 -0.960053  127.536  audio_features   \n",
       "1          -0.098201 -0.339898  0.073558   95.005  audio_features   \n",
       "2           0.909173 -0.513866 -0.087216  123.015  audio_features   \n",
       "3           1.007878 -0.362491  0.272411  120.008  audio_features   \n",
       "4           0.494030 -0.436296  0.830891  124.912  audio_features   \n",
       "5          -0.002399 -0.362491  0.272411  121.012  audio_features   \n",
       "6           0.795952 -0.211870 -0.070293  123.013  audio_features   \n",
       "7           0.508546  0.119496  0.564344  127.983  audio_features   \n",
       "8           0.505642 -0.423493 -0.925782  133.072  audio_features   \n",
       "9           0.290813 -0.279650  0.289335  176.208  audio_features   \n",
       "10          0.020826 -0.504828  0.115867  100.026  audio_features   \n",
       "11         -0.562697 -0.515372 -0.523000  129.929  audio_features   \n",
       "12          0.639185  0.021593  0.653193  114.990  audio_features   \n",
       "13          0.793049  0.850009 -0.738776  117.989  audio_features   \n",
       "14          0.897560 -0.347429  0.035480  124.981  audio_features   \n",
       "\n",
       "                                     uri  \\\n",
       "0   spotify:track:3oRuCzqdduzZ2CBhAtv8zO   \n",
       "1   spotify:track:0vbbQvmRs38P27DCSctZ7L   \n",
       "2   spotify:track:3GPYUPEP8O4cMn7mLA9RX1   \n",
       "3   spotify:track:0dE9ro91KUtV5Xi7bDPy6b   \n",
       "4   spotify:track:5YzBL3vkQnp3JbeDRRSbSQ   \n",
       "5   spotify:track:0UCU2uiUBfToI9EDdrS6aJ   \n",
       "6   spotify:track:3qQ6Y9vTezy0CZAi9QObvj   \n",
       "7   spotify:track:0c7V10APHbimDgQppV8dFz   \n",
       "8   spotify:track:1Oym7AEESwzeCjaFvFT4OC   \n",
       "9   spotify:track:05vajmV6LbINFD5fGBS9my   \n",
       "10  spotify:track:2lnplRF8NCYfdyKqaJNCG0   \n",
       "11  spotify:track:6TecGli3dA4NMIdH6C9K4m   \n",
       "12  spotify:track:0zCbXOPent461dbCEBRQwM   \n",
       "13  spotify:track:5XxFY11r0YA6Xoyh1O9WsR   \n",
       "14  spotify:track:32nw9Qc5rYjsPWGLy14Yh5   \n",
       "\n",
       "                                           track_href  \\\n",
       "0   https://api.spotify.com/v1/tracks/3oRuCzqdduzZ...   \n",
       "1   https://api.spotify.com/v1/tracks/0vbbQvmRs38P...   \n",
       "2   https://api.spotify.com/v1/tracks/3GPYUPEP8O4c...   \n",
       "3   https://api.spotify.com/v1/tracks/0dE9ro91KUtV...   \n",
       "4   https://api.spotify.com/v1/tracks/5YzBL3vkQnp3...   \n",
       "5   https://api.spotify.com/v1/tracks/0UCU2uiUBfTo...   \n",
       "6   https://api.spotify.com/v1/tracks/3qQ6Y9vTezy0...   \n",
       "7   https://api.spotify.com/v1/tracks/0c7V10APHbim...   \n",
       "8   https://api.spotify.com/v1/tracks/1Oym7AEESwze...   \n",
       "9   https://api.spotify.com/v1/tracks/05vajmV6LbIN...   \n",
       "10  https://api.spotify.com/v1/tracks/2lnplRF8NCYf...   \n",
       "11  https://api.spotify.com/v1/tracks/6TecGli3dA4N...   \n",
       "12  https://api.spotify.com/v1/tracks/0zCbXOPent46...   \n",
       "13  https://api.spotify.com/v1/tracks/5XxFY11r0YA6...   \n",
       "14  https://api.spotify.com/v1/tracks/32nw9Qc5rYjs...   \n",
       "\n",
       "                                         analysis_url  duration_ms  \\\n",
       "0   https://api.spotify.com/v1/audio-analysis/3oRu...       367667   \n",
       "1   https://api.spotify.com/v1/audio-analysis/0vbb...       225613   \n",
       "2   https://api.spotify.com/v1/audio-analysis/3GPY...       489000   \n",
       "3   https://api.spotify.com/v1/audio-analysis/0dE9...       334129   \n",
       "4   https://api.spotify.com/v1/audio-analysis/5YzB...       398151   \n",
       "5   https://api.spotify.com/v1/audio-analysis/0UCU...       266839   \n",
       "6   https://api.spotify.com/v1/audio-analysis/3qQ6...       528593   \n",
       "7   https://api.spotify.com/v1/audio-analysis/0c7V...       344920   \n",
       "8   https://api.spotify.com/v1/audio-analysis/1Oym...       290526   \n",
       "9   https://api.spotify.com/v1/audio-analysis/05va...       242709   \n",
       "10  https://api.spotify.com/v1/audio-analysis/2lnp...       360246   \n",
       "11  https://api.spotify.com/v1/audio-analysis/6Tec...       301645   \n",
       "12  https://api.spotify.com/v1/audio-analysis/0zCb...       162444   \n",
       "13  https://api.spotify.com/v1/audio-analysis/5XxF...       490725   \n",
       "14  https://api.spotify.com/v1/audio-analysis/32nw...       483960   \n",
       "\n",
       "    time_signature  \n",
       "0                4  \n",
       "1                4  \n",
       "2                4  \n",
       "3                4  \n",
       "4                4  \n",
       "5                4  \n",
       "6                4  \n",
       "7                4  \n",
       "8                4  \n",
       "9                4  \n",
       "10               4  \n",
       "11               4  \n",
       "12               4  \n",
       "13               4  \n",
       "14               4  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "initial_songs = ['luke howard portrait gallery']\n",
    "\n",
    "predict_playlist(model, initial_songs=initial_songs, predict_len=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training function\n",
    "# def train_rnn(model, train_loader, epochs, criterion, optimizer, device):\n",
    "#     \"\"\"\n",
    "#     This is the training method that is called by the PyTorch training script. The parameters\n",
    "#     passed are as follows:\n",
    "#     model        - The PyTorch model that we wish to train.\n",
    "#     train_loader - The PyTorch DataLoader that should be used during training.\n",
    "#     epochs       - The total number of epochs to train for.\n",
    "#     criterion    - The loss function used for training. \n",
    "#     optimizer    - The optimizer to use during training.\n",
    "#     device       - Where the model and data should be loaded (gpu or cpu).\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # training loop is provided\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         model.train() # Make sure that the model is in training mode.\n",
    "\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         hidden = model.initHidden()\n",
    "\n",
    "#         for batch in train_loader:\n",
    "            \n",
    "#             # get data\n",
    "#             batch_x, batch_y = batch\n",
    "            \n",
    "#             # \n",
    "#             batch_x = torch.from_numpy(batch_x).float().squeeze()\n",
    "#             batch_y = torch.from_numpy(batch_y).float()\n",
    "\n",
    "#             batch_x = batch_x.to(device)\n",
    "#             batch_y = batch_y.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             y_pred = []\n",
    "            \n",
    "#             # get predictions\n",
    "#             for x in batch_x:\n",
    "#                 y, hidden = model(x, hidden)\n",
    "#                 y_pred.append(y)\n",
    "            \n",
    "#             # perform backprop\n",
    "#             loss = criterion(y_pred, batch_y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             total_loss += loss.data.item()\n",
    "            \n",
    "#         if epoch%25 == 1:\n",
    "#             print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "\n",
    "#TODO: Create working RNN Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# from model.RnnEstimator import RNNEstimator\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = RNNEstimator(11, 30, 8)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "# train_rnn(model, processed_data, 100, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train the PyTorch Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator code\n",
    "from sagemaker.pytorch import PyTorch\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "estimator = PyTorch(entry_point=\"LSTM_Train.py\",\n",
    "                    source_dir=\"model\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    output_path = output_path,\n",
    "                    train_instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'input_features': 11,\n",
    "                        'hidden_dim': 12,\n",
    "                        'output_dim': 8,\n",
    "                        'epochs': 100\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-05 03:44:03 Starting - Starting the training job...\n",
      "2020-03-05 03:44:04 Starting - Launching requested ML instances.........\n",
      "2020-03-05 03:45:34 Starting - Preparing the instances for training.........\n",
      "2020-03-05 03:47:17 Downloading - Downloading input data\n",
      "2020-03-05 03:47:17 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,157 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,160 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,172 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,176 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,390 sagemaker-containers INFO     Module LSTM_Train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,390 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,391 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:37,391 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: LSTM-Train\n",
      "  Running setup.py bdist_wheel for LSTM-Train: started\n",
      "  Running setup.py bdist_wheel for LSTM-Train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-awuo44mk/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built LSTM-Train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: LSTM-Train\u001b[0m\n",
      "\u001b[34mSuccessfully installed LSTM-Train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:38,793 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:38,807 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"user_entry_point\": \"LSTM_Train.py\",\n",
      "    \"log_level\": 20,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-03-05-03-44-02-776\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 12,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 8,\n",
      "        \"input_features\": 11\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-999752527953/sagemaker-pytorch-2020-03-05-03-44-02-776/source/sourcedir.tar.gz\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"module_name\": \"LSTM_Train\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=12\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":12,\"input_features\":11,\"output_dim\":8}\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=11\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":12,\"input_features\":11,\"output_dim\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-03-05-03-44-02-776\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-999752527953/sagemaker-pytorch-2020-03-05-03-44-02-776/source/sourcedir.tar.gz\",\"module_name\":\"LSTM_Train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"LSTM_Train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"12\",\"--input_features\",\"11\",\"--output_dim\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=8\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-2-999752527953/sagemaker-pytorch-2020-03-05-03-44-02-776/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=LSTM_Train\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=LSTM_Train.py\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m LSTM_Train --epochs 100 --hidden_dim 12 --input_features 11 --output_dim 8\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (1.15.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, pandas\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-0.24.2 pytz-2019.3\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.8083903950613898\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.2432150756185119\u001b[0m\n",
      "\n",
      "2020-03-05 03:48:02 Uploading - Uploading generated training model\u001b[34mEpoch: 51, Loss: 0.13623916377892364\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.0919963034826356\u001b[0m\n",
      "\u001b[34m2020-03-05 03:47:56,812 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-03-05 03:48:09 Completed - Training job completed\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "# Fit estimator\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!CPU times: user 254 ms, sys: 15.1 ms, total: 270 ms\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3910e+00, -2.6351e+00, -2.7732e-01,  9.2970e-01, -4.8984e-01,\n",
       "         -1.1569e+00,  1.0857e+00, -1.2045e+00,  2.0962e+00, -5.3704e+00,\n",
       "          2.3380e-01],\n",
       "        [ 2.9102e-01, -1.3109e-01, -3.5296e-01,  6.4590e-01, -2.8399e-01,\n",
       "         -1.2541e-01, -9.2107e-01,  1.4323e+00,  6.8586e-01, -3.7562e-01,\n",
       "          6.8282e-01],\n",
       "        [ 3.8522e-01,  9.4912e-01,  6.0842e-02, -1.4610e+00,  1.5104e+00,\n",
       "          2.6102e+00, -9.2107e-01,  1.7253e+00, -7.7038e-01,  1.8358e-01,\n",
       "         -1.1925e+00],\n",
       "        [-4.4044e-01,  6.0751e-01, -5.4846e-02, -1.4123e+00, -1.6747e-01,\n",
       "          1.5519e+00,  1.0857e+00, -1.4975e+00, -8.6166e-01,  8.8285e-01,\n",
       "          3.2336e+00],\n",
       "        [ 4.9051e-01, -1.8348e-03, -6.1326e-01, -9.6511e-01, -5.3411e-01,\n",
       "         -5.2279e-01, -9.2107e-01,  5.5335e-01, -8.1149e-01,  5.3856e-01,\n",
       "         -9.0695e-01],\n",
       "        [ 6.9554e-01,  1.2076e+00, -5.0396e-02,  8.1217e-01, -7.6404e-01,\n",
       "         -7.5214e-02,  1.0857e+00, -3.2617e-02,  3.1377e-01,  1.0708e-01,\n",
       "         -4.1025e-02],\n",
       "        [ 5.7363e-01,  1.0414e+00,  3.9233e-01,  7.3477e-01, -2.6845e-01,\n",
       "          2.4687e-01,  1.0857e+00,  1.7253e+00, -5.2316e-02,  6.3584e-01,\n",
       "          2.4565e+00],\n",
       "        [ 1.2995e+00, -8.0045e-01,  6.6820e-01,  2.5032e-01, -5.9315e-01,\n",
       "         -1.0808e+00, -9.2107e-01,  2.6037e-01,  1.2050e+00,  5.6468e-01,\n",
       "          7.7759e-01],\n",
       "        [-3.9611e-01,  3.0479e-02, -1.6608e-01, -1.3865e+00,  4.1512e-01,\n",
       "         -1.7142e-01, -9.2107e-01,  2.6037e-01,  2.2675e-01,  6.0109e-01,\n",
       "         -2.0609e+00],\n",
       "        [ 3.8522e-01,  3.5823e-01, -4.7978e-01, -5.5233e-01, -4.0827e-01,\n",
       "         -1.5051e-01, -9.2107e-01,  1.1393e+00,  2.3275e-01,  5.0928e-02,\n",
       "          1.5102e-01],\n",
       "        [ 9.4490e-01, -6.3888e-01,  2.0876e+00, -1.6795e+00, -3.6943e-01,\n",
       "         -6.1899e-01, -9.2107e-01, -9.1157e-01,  1.1870e+00,  3.1171e-01,\n",
       "          1.9953e-01],\n",
       "        [-4.1828e-01,  4.3671e-01, -4.3306e-01,  1.8152e-01,  2.2406e+00,\n",
       "         -8.5324e-01, -9.2107e-01,  1.1393e+00, -8.7952e-01, -3.2984e-02,\n",
       "          4.3956e-01],\n",
       "        [ 7.4541e-01, -1.1836e+00, -2.0613e-01,  6.2297e-01, -6.9646e-01,\n",
       "         -7.2357e-01,  1.0857e+00, -9.1157e-01, -8.6283e-01, -1.1055e-03,\n",
       "          5.6152e-02],\n",
       "        [ 2.7439e-01,  6.4906e-01, -2.6397e-01,  3.3058e-01,  3.2968e-01,\n",
       "          1.1629e+00,  1.0857e+00,  1.7253e+00, -5.9724e-01,  5.9019e-01,\n",
       "         -1.8527e-01],\n",
       "        [ 1.8573e-01,  8.1986e-01, -4.0636e-01, -1.0227e-01, -4.0827e-01,\n",
       "         -1.1465e+00, -9.2107e-01,  2.6037e-01, -5.5043e-01,  5.5419e-01,\n",
       "          1.5280e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(processed_data[0][0]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(torch.Tensor(processed_data[0][0]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3910, -2.6351, -0.2773,  0.9297, -0.4898, -1.1569,  1.0857, -1.2045,\n",
       "         2.0962, -5.3704,  0.2338])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(new_tracks[-1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.3909948690196825,\n",
       " -2.635094590468726,\n",
       " -0.2773220412902482,\n",
       " 0.9296953263811546,\n",
       " -0.4898368594156362,\n",
       " -1.1569194705342014,\n",
       " 1.0856902892884872,\n",
       " -1.2045490262286025,\n",
       " 2.0961845785776654,\n",
       " -5.370441776536932,\n",
       " 0.23380331292868914]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut_pred = processed_data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3910, -2.6351, -0.2773,  0.9297, -0.4898, -1.1569,  1.0857, -1.2045,\n",
      "         2.0962, -5.3704,  0.2338])\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request.  Either the server is overloaded or there is an error in the application.</p>\n\". See https://ap-southeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-southeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-pytorch-2020-03-05-03-44-02-776 in account 999752527953 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-1a12d06da287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tracks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# for i in range(playlist_len - len(fut_pred)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request.  Either the server is overloaded or there is an error in the application.</p>\n\". See https://ap-southeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-southeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-pytorch-2020-03-05-03-44-02-776 in account 999752527953 for more information."
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "\n",
    "fut_pred = processed_data[0][0][0]\n",
    "\n",
    "playlist_len = 15\n",
    "\n",
    "new_tracks = [torch.Tensor(fut_pred).float()]\n",
    "\n",
    "print(new_tracks[-1])\n",
    "\n",
    "\n",
    "predictor.predict(new_tracks[-1])\n",
    "\n",
    "# for i in range(playlist_len - len(fut_pred)):\n",
    "#         print(i)\n",
    "#         print(predictor.predict(new_tracks[-1].values))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
